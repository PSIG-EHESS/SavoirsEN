 Inventé il y a soixante ans, l’ordinateur est devenu personnel il y a vingt-cinq ans à peine, et sa mise en réseau généralisée, avec le Web, a commencé il y a quinze ans. Ces développements technologiques ont permis la création de dispositifs d’interaction rendant les ordinateurs accessibles aux non-spécialistes, tels que les notions désormais familières de fenêtre, d’icône, de menu, de document. Ils ont engendré des mutations profondes dans nos modes d’accès à l’information, dont les plus marquantes concernent le travail savant. L’un des meilleurs exemples de ces mutations est sans doute l’évolution des pratiques de l’enseignement à l’école et à l’université : dématérialisation progressive des cahiers et des manuels scolaires, mise en ligne des cours et des travaux dirigés, généralisation des Environnements Numériques de Travail, mise en réseau des savoirs et des compétences à travers les outils d’intelligence collective, etc. Le monde de l’éducation, traditionnellement lent dans la mise en œuvre de nouvelles technologies, s’approprie d’autres façons d’apprendre, modifie le bagage intellectuel des élèves concernant les moyens et les méthodes d’accès à la connaissance et scelle ainsi la transition de la société industrielle vers la société de l’information. L’objet de ce chapitre est d’examiner quelques étapes remarquables dans l’évolution des interfaces informatiques pour la manipulation et l’organisation d’informations complexes. Il vise notamment à identifier les concepts fondateurs qui se sont imposés dans les systèmes commerciaux d’aujourd’hui ainsi que les directions actuelles de recherche qui alimenteront les futurs dispositifs. La présentation, essentiellement chronologique, est articulée autour de cinq grands moments : la vision de Doug Engelbart du rôle des ordinateurs dans le développement de l’intelligence collective ; l’essor et la généralisation de l’informatique personnelle avec le Xerox Star puis le Macintosh ; la mise en réseau généralisée des informations et des services avec le Web ; les nouvelles formes d’interaction avec les surfaces tactiles de toutes tailles et les environnements augmentés, et, enfin, une sorte de retour vers le futur avec le papier interactif. La vision de Doug Engelbart Au moment de l’invention de l’ordinateur, Vannevar Bush, alors directeur du programme de recherche de l’armée américaine, publie un article décrivant le Memex, une machine électromécanique qui permet d’archiver des documents, de les lier entre eux et de les retrouver Bush, 1945 . Ce dispositif, considéré comme l’ancêtre des systèmes hypertexte, est qualifié par Bush de « Memetic Extender », ou extension mémorielle. Il s’inscrit dans la longue histoire des dispositifs inventés par l’homme pour développer ses capacités intellectuelles en externalisant dans des artefacts ou des machines certaines de ses fonctions cognitives, comme la mémoire. Il est particulièrement intéressant de noter que le Memex se présente sous la forme d’un bureau abritant une mécanique complexe et offrant à l’utilisateur une interface constituée de dispositifs d’entrée (un clavier, à droite) et de sortie (trois écrans). Il est donc conçu pour remplacer un bureau traditionnel et s’intégrer ainsi naturellement aux flux et méthodes de travail en usage, augmentant les capacités de traitement de l’information de son utilisateur. Cette idée d’amplification des capacités humaines est reprise et largement développée par Douglas Engelbart, qui publie en 1962 un article séminal Engelbart, 1962. dans lequel il présente sa vision du rôle des systèmes informatiques pour « élever le niveau intellectuel collectif » grâce aux possibilités de traitement d’information et de collaboration qu’offrent les ordinateurs. La vision d’Engelbart est ambitieuse : face à la complexité croissante des problèmes que doit résoudre l’humanité, l’intelligence d’une seule personne ou celle d’un groupe ne sont plus suffisantes, non plus que l’« intelligence » d’une machine informatique. La seule façon de résoudre ces problèmes est d’augmenter l’intelligence collective grâce à des systèmes qui permettent aux humains de collaborer et d’exploiter les capacités des ordinateurs. Le Memex ne sera jamais construit, mais Engelbart s’attelle à la construction de systèmes d’augmentation. Comme avec le Memex, il s’agit de donner une efficacité plus grande aux situations habituelles de travail telles les réunions en mettant à la disposition des utilisateurs des outils de partage et d’édition de documents, et des moyens de communication médiatisée permettant la collaboration à distance. À la fin de 1968, Engelbart fait une démonstration publique Engelbart, 1968. de son système NLS (On-Line System) devant plus de mille personnes à San Francisco. NLS est un système hypertexte collaboratif couplé à un système de vidéoconférence. Des utilisateurs séparés de quarante-cinq kilomètres éditent sur un mode collaboratif des données organisées hiérarchiquement, comme une liste de commissions. Lorsqu’ils collaborent, ils peuvent se voir par vidéoconférence et utiliser des télépointeurs pour montrer des objets à l’écran. L’interaction avec NLS est complexe, notamment à cause de l’utilisation du clavier à accords (chord keyboard), qui permet de déclencher des commandes selon l’accord composé avec les doigts de la main gauche. Bien qu’Engelbart soit aussi l’inventeur de la souris, il a toujours été perplexe devant l’idée de systèmes conviviaux ou faciles d’utilisation. Il considère en effet que la facilité d’utilisation n’est pas un but en soi : à l’image du vélo qui nécessite un apprentissage plus long que le tricycle, mais qui est bien plus rapide, une interface adaptée aux capacités des utilisateurs mais requérant un apprentissage est plus efficace à long terme qu’une interface simpliste accessible à tout le monde. Cette philosophie est au cœur de ce qu’Engelbart appelle le « bootstrap », c’est-à-dire la capacité d’utiliser les outils non seulement pour résoudre les problèmes du moment, mais aussi pour améliorer les outils eux-mêmes et, plus généralement, « améliorer le processus d’amélioration ». Elle tranche nettement avec les développements de ce qui deviendra la bureautique, qui met dans les mains des utilisateurs des outils souvent limités et non susceptibles d’être améliorés par ces mêmes utilisateurs. Aussi la vision d’Engelbart est-elle loin d’être réalisée encore aujourd’hui (en 2010), malgré l’augmentation massive de la puissance des ordinateurs et des réseaux. De nombreuses fonctionnalités de NLS (renommé Augment lorsque Engelbart quitte le SRI en 1978) ne sont toujours pas disponibles commercialement, en particulier en ce qui concerne les outils de collaboration. L’avènement de l’informatique dite personnelle est d’ailleurs bien la preuve que la vision d’Engelbart de systèmes dédiés à la collaboration est restée largement ignorée. L’explication en est peut-être que, avec le Xerox Star et plus tard le Macintosh, décrits ci-dessous, l’informatique s’est intéressée à des catégories d’utilisateurs différentes de celles visées par Engelbart : les « knowledge workers » pour NLS, les secrétaires pour le Star, le grand public pour le Macintosh. Malgré la puissance potentielle du processus de « bootstrap », le gain immédiat que peuvent apporter des systèmes demandant peu ou pas d’apprentissage est souvent perçu comme un avantage par rapport à des systèmes plus puissants mais demandant un investissement plus important. Il n’en reste pas moins qu’Engelbart est le premier à s’être intéressé à l’évolution concrète des pratiques du travail intellectuel grâce à l’ordinateur et à avoir réalisé des prototypes fonctionnels. Et si sa vision d’une amplification de l’intellect humain reste largement à réaliser, elle sous-tend néanmoins toute l’évolution de l’informatique interactive des cinquante dernières années. Bill English utilisant la souris (main droite) et le clavier à accords (main gauche). Le Xerox Star et le début de l’informatique personnelle En 1970, grâce aux importants bénéfices obtenus avec ses brevets sur la xérographie, la société Xerox crée un laboratoire de recherche à Palo Alto, le PARC (Palo Alto Research Center). Xerox veut non seulement poursuivre le développement de sa technologie, mais aussi anticiper l’expiration des brevets et se lancer dans les systèmes bureautiques. De fait, le marché des photocopieurs lui donne un accès privilégié au secteur tertiaire. Pendant plus de trente ans, le Xerox PARC sera le théâtre d’un nombre spectaculaire d’inventions qui ont marqué l’histoire de l’informatique, à tel point que le slogan favori des chercheurs du PARC, attribué à Alan Kay, l’un de ses fondateurs, est : « La meilleure façon de prédire le futur, c’est de l’inventer. » Le Xerox Star est la première station de travail graphique commercialisée de l’histoire Smith et al., 1982 ; Johnson et al., 1989. . Elle est le résultat d’un programme de recherche de près de dix ans qui a vu le développement de multiples prototypes, dont l’Alto, et l’invention de tous les concepts de l’informatique interactive moderne. Alan Kay, considéré comme le père de l’informatique personnelle, a largement influencé ces travaux. Sa vision n’est pas très éloignée de celle d’Engelbart : il s’agit de fournir à l’utilisateur non pas des applications préprogrammées, mais un ensemble d’outils pour construire son propre environnement. Cette vision sera à la base du langage et de l’environnement de programmation graphique Smalltalk, que Kay continue de développer aujourd’hui sous le nom de Squeak. Pour le Xerox Star cependant, qui n’est plus un projet de recherche mais un projet commercial, cet objectif sera largement laissé de côté. La cible du Star est la secrétaire de direction, qui doit manipuler un grand nombre de documents, les compiler pour son patron, les transmettre aux autres employés, etc. Il s’agit d’un travail de bureau avec une forte valeur ajoutée. Le Xerox Star présente donc une interface métaphorique dans usuels du travail de bureau sont représentés à l’écran : casiers pour le courrier, dossiers pour ranger les documents, corbeille à papier, calendrier, etc. (voir http://visite.imusee.info/Renaissance_Files/droppedImage_1.png). Les documents eux-mêmes sont présentés dans des fenêtres que l’on peut manipuler comme les feuilles de papier sur un bureau. Ces documents peuvent contenir du texte, des images, des tableaux, des graphiques et ils apparaissent à l’écran de façon identique à leur version imprimée : on parle de principe WYSIWYG (What You See Is What You Get) – « ce que vous voyez est ce que vous avez ». Les icônes, les fenêtres et le contenu des documents peuvent être manipulés de façon uniforme grâce à une souris qui permet de les désigner à l’écran et des touches de fonction aisément accessibles de part et d’autre de la partie alphabétique du clavier. Le Star s’inspire ainsi de l’interface bimanuelle de NLS, en remplaçant le clavier à accords par des touches de fonction. La force de l’interface du Star est de permettre de réaliser des manipulations complexes à partir d’un petit nombre de fonctions, accessibles par le clavier pour la plupart : Déplacer, Copier, Détruire, Ouvrir, Chercher, Annuler, Propriétés, Caractères, etc. Ainsi la métaphore opère-t-elle non seulement sur les objets présentés, mais également sur la façon de les manipuler. Par exemple, la plupart des objets ont des propriétés, qui dépendent du type de l’objet. Une seule fonction, « Propriétés », affiche une feuille de propriétés spécifique à l’objet affiché sous le curseur de la souris. Comme dans toutes les interfaces réussies, l’important est ce qui ne se voit pas, c’est-à-dire ce que les concepteurs ont réussi à dissimuler ou à rendre « transparent », intuitif pour l’utilisateur. Ainsi, l’interface du Star est fondée sur la notion de document, et il n’y a pas à proprement parler de notion d’application. Comme les documents du monde réel, les documents du Star peuvent contenir du texte, des formules mathématiques, des tableaux, des graphiques. Ils sont créés à partir de modèles, et il est possible d’insérer tout type de contenu n’importe où dans un document. On peut coupler un graphique à un tableau de telle sorte que le graphique soit mis à jour immédiatement lorsque le tableau est modifié. La métaphore du Star n’est donc pas une copie du monde réel : elle s’inspire de celui-ci pour le prolonger de façon cohérente et aisément compréhensible par l’utilisateur. D’autre part le Star est fondamentalement une machine ouverte au réseau informatique, à tel point qu’il est pratiquement invisible pour l’utilisateur. Celui-ci peut configurer son environnement en parcourant un catalogue de ressources accessibles à travers le réseau local : serveurs de fichiers, imprimantes, etc. Il installe ces ressources sur le bureau électronique, où elles apparaissent sous forme d’icônes et restent accessibles d’une session à l’autre. Ainsi la différence entre ressource locale et ressource distante est-elle invisible. Là aussi, un effort particulier est fait pour que la technologie soit au service de la cohérence du système du point de vue de l’utilisateur. Tous les concepts des interfaces modernes sont présents dans le Star. À vrai dire, le Star est encore en avance par rapport aux interfaces actuelles : la transparence du réseau, l’environnement centré sur les documents, l’utilisation d’un petit nombre de commandes qui s’appliquent à un grand nombre de contextes sont autant de caractéristiques du Star qui ne sont toujours pas présentes dans les environnements actuels. Pourtant le Star fut un échec commercial : système trop cher, cible marketing mal évaluée et surtout incapacité de Xerox à sortir de son marché historique des photocopieurs. Le Macintosh et les limites de la métaphore du bureau Après l’échec du Star, le succès du Macintosh d’Apple marque le point de départ de l’informatique personnelle pour le grand public. À première vue, l’interface du Macintosh est largement inspirée du Star : des fenêtres qui affichent des documents, des icônes sur le bureau virtuel, une souris, des commandes accessibles dans des menus et, très rapidement, la connectivité au réseau local. Pourtant, le concept est, dès le départ, différent Raskin, 2000. , et une grande partie de l’interface du Macintosh est dérivée du Lisa Perkins et al., 1997. . Ainsi, alors que le Star utilise peu les menus en se concentrant sur les fonctions génériques accessibles au clavier, le Macintosh reprend la barre de menus du Lisa qui offre, en haut de l’écran, un accès à toutes les commandes du logiciel. D’autre part, tandis que le Star est centré sur les documents, le Macintosh est centré sur la notion d’application, dédiée à la manipulation d’un type de document. Certes, il est possible de copier les éléments d’un document dans un document d’un autre type, mais cette copie n’est pas éditable dans le document où elle est collée : il faut revenir au document initial et refaire l’opération de copier-coller. Enfin, la transparence au réseau n’est pas vraiment au rendez-vous. D’un autre côté, alors que le Star était une machine fermée, pour laquelle seul Xerox pouvait développer du logiciel, le Macintosh est une machine ouverte aux développeurs extérieurs. C’est probablement la raison de son succès (et de celui du PC Windows) : tandis que le Star est dédié à un usage unique, le Macintosh dispose de logiciels couvrant une gamme d’activités de plus en plus large. Il est particulièrement apprécié dans les milieux de la production audiovisuelle, des médias, de l’édition et, de façon générale, dans les domaines artistiques et culturels. Le design du matériel et du logiciel montre en effet un goût du détail, une esthétique, une flexibilité, mais aussi une performance et un concept tout-en-un qui sont appréciés de ces publics. Malgré des évolutions régulières, l’interface du Macintosh n’a pratiquement pas changé depuis l’origine, en tout cas au niveau de ses principes. Les documents sont organisés en dossiers dans une structure strictement hiérarchique qui oblige l’utilisateur à imaginer un système de classement rigoureux. L’interaction est une évolution des principes du Star : l’utilisateur désigne le ou les objets d’intérêt avec la souris, définissant ainsi une « sélection » d’objets ; il active ensuite une commande par l’intermédiaire des menus déroulants de la barre de menus, d’un menu contextuel, d’une palette ou d’un raccourci clavier. Éventuellement, une boîte de dialogue apparaît pour spécifier des paramètres supplémentaires de la commande. Enfin la commande est appliquée à la sélection, modifiant éventuellement celle-ci. Une autre forme d’interaction est aussi largement utilisée : le « drag-and-drop » ou « cliquer-tirer », qui consiste à prendre un objet et le déplacer au-dessus d’un autre objet, ce qui a pour effet de déclencher une commande dépendant de l’objet déplacé et de la destination choisie. Cette commande est souvent une opération de déplacement ou de copie de l’objet source vers l’objet destination et s’inspire de notre interaction dans le monde physique : prendre un objet pour le poser ailleurs. De façon générale, les interfaces graphiques popularisées par le Macintosh et reprises depuis par Microsoft Windows et Linux ont atteint un degré important de stabilité et de similarité. L’avantage indéniable est que tout utilisateur peut aisément s’approprier un nouveau logiciel, voire changer de plate-forme. L’inconvénient est que cette standardisation limite l’innovation, alors même qu’il existe de nouvelles méthodes d’interaction plus efficaces et que la métaphore du bureau montre ses limites Beaudouin-Lafon, 2000. . Ainsi, la généralisation des palettes et des menus multiplie le nombre de commandes disponibles, tandis que le Xerox Star avait adopté une approche minimaliste, grâce à l’utilisation de commandes génériques. Certaines techniques d’interaction comme les menus circulaires (pie menus) inventés en 1986 par Don Hopkins Callahan et al., 1988. et améliorés en 1993 par Gordon Kurtenbach Kurten-Bach et Buxton, 1993. peuvent accélérer la sélection dans un menu d’un facteur trois. De façon similaire les « toolglasses Bier et al., 1993. », des palettes semi-transparentes manipulées par la main non dominante, peuvent améliorer la performance de l’interaction de 40 % par rapport aux palettes classiques. Les nombreuses palettes de l’interface de Microsoft Word sur le Macintosh en 2001. Par ailleurs, la quantité de documents archivés par les utilisateurs augmente de façon exponentielle, et il devient impossible de les gérer avec un simple système de dossiers hiérarchiques. Beaucoup d’utilisateurs s’en remettent au moteur de recherche qui équipe désormais ces environnements (Spotlight sur le Macintosh) pour retrouver un document non pas en allant le chercher là où il est, mais en déléguant la recherche à l’ordinateur. Cette approche est très efficace lorsqu’elle rapporte le document recherché, mais très frustrante lorsque l’utilisateur sait que le document existe mais qu’il ne peut le trouver. La recherche d’un document devient alors une tâche à part entière, qui souvent interrompt la tâche principale et en fait perdre le fil. Enfin, le nombre d’applications et de fenêtres présentes simultanément à l’écran augmente alors que la taille des écrans reste relativement stable, provoquant un encombrement de l’espace disponible. Les « Spaces » et la technique « Exposé » du Macintosh permettent de pallier ces problèmes en répartissant les fenêtres sur plusieurs bureaux virtuels et en affichant des miniatures des fenêtres, mais là encore on arrive rapidement aux limites de la mémoire à court terme lorsqu’une tâche est interrompue par de multiples manipulations de fenêtres. D’autres techniques telles que celles du logiciel de fenêtrage Metisse Chapus et Roussel, 2005. permettent de manipuler les fenêtres comme des feuilles de papier réelles, par exemple en les roulant pour faire apparaître ce qui est dessous, évitant ainsi de nombreuses manipulations. En vingt ans, l’écran de l’ordinateur, qui délimitait jadis un monde relativement petit et dont l’utilisateur pouvait conserver une image mentale précise, est devenu une petite fenêtre sur un vaste entrepôt où s’accumulent des documents de toutes sortes. L’ordinateur ne sert plus seulement à des tâches bureautiques de fabrication de documents, c’est aussi un centre de communication (courrier électronique, messageries instantanées, etc.), un guichet pour tous les services de commerce en ligne, un centre de stockage multimédia pour les photos, les films, la musique, etc. La métaphore du bureau n’a jamais été conçue pour des usages aussi variés ni pour passer à l’échelle de dizaines ou centaines de milliers de documents. De toute évidence, de nouveaux paradigmes sont nécessaires pour apporter des solutions nouvelles à ces problèmes et redonner le contrôle à l’utilisateur qui se sent de plus en plus dépassé par la complexité qui lui est imposée. À gauche : un menu circulaire permet une sélection rapide par un geste directionnel ; à droite : une « toolglass » ou palette semi-transparente, manipulée avec la main non dominante, permet de colorer un dessin en cliquant à travers la palette sur la zone à colorier. Le World Wide Web et l’information répartie Ces problèmes sont d’autant plus criants que les documents désormais à portée de main ne sont plus seulement « dans » l’ordinateur, mais n’importe où dans le monde, accessibles à travers le Web. Le Web a radicalement modifié les pratiques de travail en remplaçant de nombreux déplacements physiques dans les bibliothèques, les librairies, les administrations et les commerces par des interactions avec des machines à travers les navigateurs Web. Cette commodité d’accès a cependant un coût : elle nous prive des interactions avec les interlocuteurs humains dans ces différents lieux, de l’accès à leurs savoirs et compétences. Même si ceux-ci sont en partie compensés par les moyens de communication nouveaux que le Web et Internet en général mettent à notre disposition (forums de discussion, listes de distribution, sites sociaux, etc.), accéder aux milliards de documents disponibles sur le Web à travers les fenêtres d’un navigateur pose de nombreux problèmes. Un premier ensemble de problèmes est lié à la difficulté de s’approprier les documents du Web comme on s’approprie des ouvrages ou documents que l’on achète dans une librairie. Le problème principal est la fluidité du Web : un document peut changer d’adresse, son contenu peut évoluer, il peut être temporairement inaccessible, etc. Il s’ensuit que les trois opérations les plus fréquentes sur un document dont on n’est pas l’auteur, à savoir l’archiver, l’annoter et le citer, ne sont pas réalisables simplement avec les documents extraits du Web. Pour archiver un document, on peut créer un marque-page ou un favori, mais les outils de rangement et de recherche offerts par les navigateurs sont limités. En conséquence, on préfère souvent télécharger le document pour le ranger dans son propre système de fichiers, au risque de perdre trace de son origine. Pour annoter un document, il faut également le télécharger et annoter sa copie locale. Pour le citer enfin, il faut copier son contenu et perdre trace de l’origine de la citation. Pourtant, certaines solutions ont été imaginées pour permettre ces usages de façon plus naturelle. Dans la première version du navigateur Mosaic, il était possible d’annoter les pages Web à l’intérieur du navigateur. Les annotations étaient stockées sur la machine de l’utilisateur et rappelées lorsque la page était à nouveau consultée. Le seul problème de cette approche est que lorsque la page change, les annotations peuvent devenir obsolètes. Ce problème pourrait être résolu si l’utilisateur pouvait enregistrer une copie locale de la page et avoir la possibilité de mettre à jour ses annotations lorsque la page change. Concernant la citation, Ted Nelson, l’inventeur du terme « hypertexte », a proposé dès les années 1970, sous le nom de Xanadu, le concept d’un système mondial pour la publication en réseau de documents Nelson, 1992. . Ce système est fondé sur un modèle plus riche et plus complexe que celui du Web actuel : il permet notamment de parcourir les liens « à l’envers », afin de retrouver directement toutes les pages qui citent une page donnée. Xanadu implémente aussi le concept de « transclusion », qui permet d’inclure le contenu d’un document source sans le copier, et prévoit même un système de redevance pour l’accès à de tels contenus. Une deuxième catégorie de problèmes liés à l’usage du Web est la publication des documents. Alors que Tim Berners-Lee envisageait un système où tout le monde pouvait être lecteur mais aussi auteur Berners-Lee et al., 1994. , la réalité actuelle est qu’il est bien plus facile d’être lecteur qu’auteur. Pourtant, la version originale du navigateur Web, créée par Berners-Lee pour la plate-forme NeXT, intégrait des fonctions d’édition permettant de modifier une page comme on modifie un document texte, depuis le navigateur, et de mettre à jour celle-ci sur le serveur d’origine, à condition bien sûr d’avoir les droits d’accès nécessaires. Comme ces facilités d’édition et de publication ne sont pas présentes dans les navigateurs, elles sont progressivement apparues à l’intérieur des pages Web elles-mêmes. C’est par exemple le cas dans les logiciels de blog ou les sites de réseaux sociaux qui permettent de créer le contenu par l’intermédiaire de formulaires. La conséquence est que le Web contient désormais non seulement des documents, mais également des applications réelles qui reproduisent les interfaces auxquelles nous sommes habitués sur nos environnements de bureau. À titre d’exemple, l’application Web 280slides.com reproduit dans un navigateur l’interface de l’application de création de présentations Keynote d’Apple. L’évolution du Web d’une plate-forme de publication de documents vers une plate-forme de distribution d’applications conduit à encourager les utilisateurs à déposer leurs documents sur les sites qui hébergent ces applications, et non plus sur le disque dur de leur ordinateur personnel : le courrier électronique sur GMail, les documents sur Google Docs, les photos sur Flickr, les vidéos sur YouTube, etc. Chacune de ces applications gère son propre espace de stockage, à travers sa propre interface et sans possibilité d’interopérabilité simple avec le bureau virtuel traditionnel, ses dossiers et ses documents. Cette évolution tend in fine à renverser la logique du Web : d’un côté, l’utilisateur récupère les documents qu’il a consultés sur le Web pour être sûr de ne pas les perdre, de l’autre, il cède la gestion de ses propres documents à des services tiers, au risque d’ailleurs d’en perdre la propriété ! De toute évidence, le décalage croissant entre ces nouvelles pratiques et leur équivalent dans le monde physique est une source de difficulté pour les utilisateurs, qui passent une proportion croissante de leur temps à des tâches de transfert, de recherche et d’organisation de leurs documents. C’est pour pallier ces problèmes que de nouvelles approches sont étudiées dans les laboratoires de recherche. Les environnements augmentés et les surfaces tactiles En 1991, Mark Weiser présente dans un article séminal sa vision de l’informatique du xxi e siècle Weiser, 1991. : Ubiquitous Computing, ou l’accès à l’information en ligne omniprésent dans l’environnement physique, grâce à des ordinateurs et des écrans de toutes tailles. Cette vision préfigure clairement l’avènement des smartphones, PDAs, TabletPC et autres NetBooks, mais elle contient l’idée d’une forte intégration entre ces différents dispositifs qui est loin d’être réalisée aujourd’hui. L’objectif de Weiser est en effet de pouvoir passer de façon fluide d’un support à l’autre selon le contexte d’utilisation, de faire en sorte que les documents suivent les utilisateurs là où ils en ont besoin et que les ressources soient aisément partagées entre les participants. Cela nécessite une révision profonde des infrastructures actuelles, qui tendent à balkaniser nos environnements informatiques en produits propriétaires incompatibles. La vision de Weiser trouve un prolongement naturel dans la notion de réalité augmentée Wellner et al., 1993. , qui a pour but d’intégrer l’information directement au sein des objets physiques usuels, brouillant ainsi les frontières entre mondes physique et informatique, afin de mieux tirer parti des savoir-faire des utilisateurs. Ainsi, le Digital Desk Wellner, 1993. de Pierre Wellner augmente le bureau traditionnel et les objets posés dessus. Grâce à un projecteur et à une caméra montés au-dessus du bureau, l’ordinateur peut suivre les manipulations d’objets physiques posés sur le bureau, par exemple les feuilles de papier, et projeter des informations ou des applications, comme une calculette, que l’on peut manipuler à même le bureau. Que ce soit l’Ubicomp ou la réalité augmentée, l’interaction repose largement sur l’utilisation de gestes familiers sur des surfaces interactives diverses ou dans l’espace Bolt, 1980. . L’ordinateur classique avec son clavier, son écran et sa souris disparaît au profit de dispositifs mieux intégrés à l’environnement physique et capables d’une certaine perception de cet environnement afin de faciliter les activités de l’utilisateur. Par exemple, un ordinateur portable peut reconnaître la présence d’un projecteur dans une pièce et offrir à l’utilisateur de s’y connecter sans qu’il ait besoin de réaliser une connexion physique ni de manipuler une télécommande. La plupart de ces nouveaux dispositifs reposent sur l’utilisation d’interfaces dites gestuelles, qui capturent les mouvements des doigts ou d’objets au contact d’une surface interactive. Cette interaction gestuelle est par nature plus riche que l’interaction à la souris qui ne traite que des positions discrètes : avec l’interaction gestuelle, il est possible de reconnaître des tracés ou des gestes, et l’interaction peut se faire avec plusieurs points de contact, comme cela a été popularisé depuis 2007 avec l’iPhone puis l’iPad d’Apple. Mais l’interaction gestuelle pose le problème de l’invisibilité a priori du vocabulaire gestuel, au contraire d’un système de menu qui peut être parcouru par l’utilisateur. Des techniques comme OctoPocus Bau et Mackay, 2008. permettent cependant de résoudre ce problème tout en améliorant le taux de reconnaissance du système. L’iPad d’Apple permet une interaction gestuelle avec plusieurs points de contact. L’interaction gestuelle est également très adaptée à d’autres surfaces comme les tables interactives ou les murs interactifs. Les tables offrent l’avantage d’une situation de travail habituelle et invitent à la collaboration. Selon la technologie utilisée, elles peuvent également reconnaître la présence d’objets physiques et encourager ainsi une interaction dite tangible, où des objets physiques représentent des objets informatiques. Par exemple, un téléphone posé sur la table peut être reconnu et donner accès à son répertoire, tandis qu’un appareil photo permettra de visualiser directement les photos qu’il contient. Dans le cas du mur interactif, on revient à une surface verticale. Sa taille et sa résolution permettent toutefois des usages impossibles avec les écrans de nos ordinateurs actuels. Ainsi le mur d’écran de la plate-forme WILD, installée au Laboratoire de recherche en informatique à Orsay, permet-il d’afficher 131 millions de pixels (20 480 × 6 400) sur une surface de 5,50 m × 1,80 m. Comme la table, le mur invite au travail collaboratif : il permet l’accès immédiat à un grand nombre de documents, tout comme il permet de passer d’une vue d’ensemble à une vue détaillée simplement en se déplaçant physiquement, sans manipulation d’une barre de défilement ou d’une roulette de souris. Le mur haute résolution de la plateforme WILD permet de manipuler des documents complexes en très haute résolution. Au-delà de l’intérêt de chacun de ces dispositifs, c’est leur combinaison qui permet d’envisager les usages les plus riches et les plus novateurs. En combinant une table et un mur interactifs, on pourra rechercher les documents d’intérêt sur la table et les afficher sur le mur, ou l’inverse. En munissant les utilisateurs de dispositifs portables et en suivant leur position dans l’espace, il sera possible de glisser des données présentes sur la table vers le dispositif portable, de se déplacer vers le mur et de les déposer à l’endroit de son choix. À l’inverse de la réalité virtuelle qui enferme les utilisateurs dans un univers déconnecté du monde physique, la réalité augmentée et les approches Ubicomp tirent parti du monde physique et l’augmentent de capacités de traitement de l’information. Ces approches répondent finalement à la vision d’Engelbart : fournir des outils que les utilisateurs peuvent s’approprier pour améliorer leur propre processus d’augmentation. Alors que la métaphore du bureau créait une sorte de réalité virtuelle, accessible uniquement du bout du curseur de la souris ou des touches du clavier, ces nouvelles approches rendent l’information plus tangible, plus matérielle, plus concrète. Une étape supplémentaire dans cette direction est en train d’être franchie avec l’avènement du papier interactif. Retour vers le futur : le papier interactif S’il est un objet physique qui est au cœur des activités savantes, c’est bien le papier. Curieusement, toute l’histoire de l’informatique interactive a traité le papier comme un périphérique (on le numérise en entrée, on imprime dessus en sortie), et les tentatives pour s’en débarasser ont été vaines Sellen et Harper, 2001. . Les propriétés du papier sont en effet remarquables : il est peu cher, robuste, flexible, de très haute résolution et il ne tombe pas en panne. Il fait partie de notre vie, du livre de La Pléiade à la nappe de restaurant en passant par les magazines, livres, notices, cahiers, carnets, feuilles volantes, cartes et Post-it qui prennent part à la moindre de nos activités quotidiennes. Diverses technologies sont en passe de rendre au papier sa juste place dans notre vie numérique. La première richesse du papier est qu’il est possible d’écrire librement dessus et de conserver ce qui y est écrit. La technologie de la société Anoto, commercialisée notamment par Logitech, Nokia et Livescribe, permet de capter avec grande précision ce que l’on écrit sur un papier spécial avec un stylo adapté : le papier contient une fine grille de points, différente sur chaque page, et le stylo repère la position de la pointe sur la grille de points grâce à une micro-caméra. Les données enregistrées peuvent ensuite être transmises et traitées sur un ordinateur. Dans le cas du stylo Livescribe, il est possible de télécharger des mini-applications dans le stylo lui-même. Par exemple, une application « calculette » reconnaît le tracé des chiffres et des quatre opérations. Lorsque l’on écrit « 2 + 3 = », le stylo affiche le résultat dès que le signe « égale » est tracé. Le stylo peut également enregistrer le son ambiant, qui est synchronisé avec les données écrites : en tapant un mot, le stylo rejoue le son enregistré au moment où le mot était écrit. On imagine aisément l’intérêt de ce dispositif, par exemple pour annoter des documents de façon écrite ou orale et pour conserver ou transmettre les annotations (la grille de points peut être ajoutée lors de l’impression de n’importe quel document). Une autre forme de papier interactif est issue des travaux de Nick Sheridon à Xerox PARC dans les années 1970 : il s’agit d’un film plastique un peu plus épais que du papier, renfermant des billes bicolores, qui peut enregistrer et afficher une image indéfiniment, sans consommer d’énergie. Il s’agit en quelque sorte d’une feuille qui peut être effacée et récrite à l’infini. Des technologies proches sont utilisées aujourd’hui dans certains lecteurs de livres électroniques tels que le Reader de Sony et le Kindle d’Amazon, mais il n’existe pas encore de produit commercial permettant d’interagir directement avec ces supports. Wendy Mackay travaille depuis longtemps sur le papier interactif ; elle a créé plusieurs prototypes destinés notamment aux chercheurs en biologie qui consignent leurs recherches dans un cahier de laboratoire. Les chercheurs sont attachés au cahier de papier, qui ne peut être complètement informatisé car ils y collent des échantillons biologiques, des résultats imprimés par des appareils de mesures, etc. Dans l’un des prototypes, le A-book Mackay et al., 2002. , un écran portable est utilisé comme une lentille magique pour interagir avec le contenu du cahier : l’écran affiche le contenu de la page sur laquelle il se trouve, donnant l’illusion d’un écran transparent. L’utilisateur peut alors cliquer, par exemple, sur un mot qui est reconnu comme une procédure, et l’écran indique la page où la procédure est décrite. D’autres prototypes utilisent la technologie Anoto pour établir aisément des liens entre les données consignées dans le cahier et des données en ligne, comme les résultats des logiciels d’analyse du génome. Grâce au papier interactif, on peut s’attendre à franchir une nouvelle étape dans la meilleure intégration entre les mondes physique et électronique. Comme l’évoque Engelbart et comme le souligne Mackay Mackay, 2000. , ces technologies sont susceptibles de co-adaptation par les utilisateurs : alors qu’elles offrent à ces derniers des possibilités nouvelles, ils se les approprient également de façon inattendue grâce à leur flexibilité. Ces appropriations créent de nouveaux usages et, à leur tour, de nouveaux détournements. Les technologies interactives sont les plus puissantes lorsqu’elles ménagent des espaces pour la coadaptation, lorsqu’elles encouragent et facilitent le « bootstrap ». Avant les interfaces graphiques, les interfaces à ligne de commande tiraient leur puissance des langages utilisés, mais elles n’étaient pas accessibles au grand public. Les interfaces graphiques et la métaphore du bureau ont permis une large appropriation, au prix toutefois d’une puissance d’expression plus limitée, qui se traduit par de nombreuses manipulations fastidieuses et répétitives. Les nouvelles interfaces visent à mieux exploiter les capacités sensorimotrices de l’être humain afin que celui-ci puisse à son tour mieux exploiter les capacités de calcul et de stockage des ordinateurs. Alors que la transition vers les interfaces graphiques a été brutale, il est peu probable qu’une nouvelle rupture de ce type se produise. En effet ces interfaces sont aujourd’hui trop répandues, et notre vie dépend tellement d’elles que l’on ne peut pas les remplacer du jour au lendemain. La future révolution se fera donc en douceur : elle a déjà été abordée par les smartphones tels que l’iPhone, elle sera poursuivie demain par les surfaces interactives telles que les tablettes, les tables et les murs, qui commencent à devenir des produits commerciaux. À titre d’exemple, le gouvernement anglais est en train d’équiper massivement les écoles de tableaux interactifs. Demain ils seront aussi sans doute présents dans les chambres des écoliers et interconnectés par Internet. Les enfants pourront y faire leurs devoirs, mais aussi jouer, découvrir, expérimenter. Les manuels scolaires seront des e-books, signant la fin des cartables pesants, les cahiers utiliseront eux aussi du papier interactif qui permettra aux professeurs de faire les corrections à distance. Les travailleurs intellectuels utiliseront aussi massivement ces technologies. Dans les salles de réunion traîneront des surfaces interactives pour prendre des notes, récupérer des documents à présenter, enregistrer les présentations. Bien entendu, il restera de nombreux ordinateurs classiques pour certaines tâches. La saisie de texte au clavier a encore de beaux jours devant elle, et beaucoup seront attachés à consulter leur e-mail ou à naviguer sur le Web comme au bon vieux temps. Finalement, le prix déclinant, le grand public adoptera aussi progressivement ces outils. Tout aura changé, et rien n’aura changé : les livres, les cahiers, les tableaux, les tables, les murs seront toujours là, ils auront la même fonction mais ils ne seront plus passifs, ils seront devenus interactifs, contribuant au rêve d’Engelbart de donner à chacun les moyens d’élever ses capacités intellectuelles personnelles et collectives. Sources  Bau et Mackay, 2008 : Olivier Bau et Wendy E. Mackay, « OctoPocus : a Dynamic Guide for Learning Gesture-Based Command Sets », in Proceedings of the 21st Annual ACM Symposium on User interface Software and Technology, UIST ‘08 (Monterey, CA, 19-22 octobre 2008), New York, p. 37-46.  Beaudouin-Lafon, 2000 : Michel Beaudouin-Lafon, « Instrumental Interaction : an Interaction Model for Designing Post-WIMP User Interfaces », in Proceedings of the annual SIGCHI Conference on Human Factors in Computing Systems, CHI ‘00 (La Haye, Pays-Bas, 1er-6 avril 2000), New York, p. 446-453.  Berners-Lee et al., 1994 : Tim Berners-Lee, Robert Cailliau, Ari Luptonen, Henrik Frystyk Nielsel et Arthur Secret, « The World Wide Web », Communications of the ACM, vol. 37 (8), août, New York, p. 76-82.  Bier et al., 1993 : Eric A. Bier, Maureen C. Stone, Ken Pier, William Buxton et Tony D. DeRose, « Toolglass and Magic Lenses : the See-Through Interface », in Proceedings of the 20 th Annual Conference on Computer Graphics and Interactive Techniques (Anaheim, CA, 2-6 août 1993), SIGGRAPH ‘93, New York, p. 73-80.  Bolt, 1980 : Richard A. Bolt, « Put-That-There : Voice and Gesture at the Graphics Interface », in Proceedings of the 7 th Annual Conference on Computer Graphics and Interactive Techniques (Seattle, WA, 14-18 juillet 1980), SIGGRAPH ‘80, New York, p. 262-270.  Bush, 1945 : Vannevar Bush, « As We May Think », The Atlantic Monthly, vol. 176, juillet, p. 101-108. Réédité dans Life Magazine, novembre 1945. Réédité et commenté dans ACM interactions, vol. 3 (2), New York, 1996, p. 35-67.  Callahan et al., 1988 : John Callahan, Don Hopkins, Mark Weiser et Ben Shneiderman, « An Empirical Comparison of Pie vs. Linear Menus », in Proceedings of the annual SIGCHI Conference on Human Factors in Computing Systems, CHI ‘88 (Washington D.C., 15-19 mai 1988), New York, p. 95-100.  Chapuis et Roussel, 2005 : Olivier Chapuis et Nicolas Roussel, « Metisse is not a 3D Desktop », in Proceedings of the 18th ACM Symposium on User Interface Software and Technology, UIST ‘05 (Seattle, WA, 23-26 octobre 2005), New York, p. 13-22.  Engelbart, 1962 : Douglas C. Engelbart, Augmenting Human Intellect : A Conceptual Framework, Summary Report on Contract AF 49(638)-1024, Stanford Research Institute, octobre.  Engelbart, 1968 : D. C. Engelbart, A Research Center for Augmenting Human Intellect, 90-min. video recording, live online hypermedia demonstration/presentation at the Fall Joint Computer Conference, San Francisco, CA, 9 décembre.  Johnson et al., 1989 : Jeff Johnson, Teresa L. Roberts, William Verplank, David C. Smith, Charles H. Irby, Marian Beard et Kevin Mackey, « The Xerox “Star” : A Retrospective », IEEE Computer, vol. 22 (9), septembre, p. 11-29. Réédité dans Ronald M. Baecker, Jonathan Grudin, William Buxton et Saul Greenberg, Human Computer Interaction : Toward the Year 2000, San Francisco, 1995, p. 53-70.  Kurtenbach et Buxton, 1993 : Gordon Kurtenbach et William Buxton, « The Limits of Expert Performance Using Hierarchic Marking Menus », in Proceedings of the annual SIGCHI Conference on Human Factors in Computing Systems, INTERCHI ‘93 (Amsterdam, 24-29 avril 1993), New York, p. 482-487.  Mackey, 2000 : Wendy E. Mackey, « Responding to Cognitive Overload : Co-adaptation Between Users and Technology », Intellectica, vol. 30 (1), p. 177-193. Mackey et al., 2002 : Wendy E. Mackey, Catherine L etondal, Guillaume Pothier, Kaare B ø egh et Hans Erik S ørensen, « The Missing Link : Augmenting Biology Laboratory Notebooks », in Proceeding of the annual ACM Symposium on User Interface Software and Technology, UIST ‘02 (Paris, 27-30 octobre 2002), New York, p. 41-50.  Nelson, 1992 : Ted Nelson, Literary Machines : The report on, and of, Project Xanadu concerning word processing, electronic publishing, hypertext, thinkertoys, tomorrow’s intellectual revolution, and certain other topics including knowledge, education and freedom, Sausalito (CA).  Perkins et al., 1997 : Roderick Perkins, Dan Smith Keller et Frank Ludolph, « Inventing the Lisa User Interface », ACM Interactions, vol. 4 (1), New York, p. 41-53.  Raskin, J. 2000 : Jef Raskin, The Humane Interface, Addison Wesley.  Sellen et Harper, 2001 : Abigail J. Sellen et Richard H. R. Harper, The Myth of the Paperless Office, Cambridge (Mass.).  Smith et al., 1982 : David Canfield Smith, Charles Irby, Ralph Kipball et Eric Harslem, « The Star User Interface : an Overview », in Proceedings of the 1982 National Computer Conference, AFIPS (Houston, Texas, 7-10 juin 1982), New York, p. 515-528.  Sutherland, 1963 : Ivan E. Sutherland, « SketchPad : A Man-Machine Graphical Communication System », in Proceedings of the Spring Joint Computer Conference, AFIPS ‘63 (Detroit, Michigan, 21-23 mai 1963), New York, p. 329-346.  Weiser, 1991 : Mark Weiser, « The Computer for the Twenty-First Century », Scientific American, vol. 265 (3), septembre, p. 94-104.  Wellner et al., 1993 : Pierre Wellner, Rich Gold et Wendy Mackay, « Special Issue on Computer-Augmented Environments : back to the Real World », Communications of the ACM, vol. 36 (7), juillet, New York.  Wellner, 1993 : Pierre Wellner, « Interacting with Paper on the DigitalDesk », Communications of the ACM, vol. 36 (7), juillet, New York, p. 87-96. Autres références  Baecker et al., 1995 : Ronald M. Baecker, Jonathan Grudin, William A. S. Buxton et Saul Greenberg, Human-Computer Interaction : Toward the Year 2000, San Francisco (CA).  Beaudouin-Lafon, 2006 : Michel Beaudouin-Lafon (dir.), Section Interaction Homme-Machine, Encyclopédie de l’Informatique et des Systèmes d’Information, dir. Jacky Akoka et Isabelle Comyn-Wattiau, Paris.  Erickson et McDonald, 2008 : Thomas Erickson et David W. McDonald (dir.), HCI Remixed : Reflections on Works That Have Influenced the HCI Community, Cambridge (Mass.).  Moggridge, 2007 : Bill Moggridge, Designing Interactions, Cambridge (Mass.).  Shneiderman et Plaisant, 2009 : Ben Shneiderman et Catherine Plaisant, Designing the User Interface : Strategies for Effective Human-Computer Interaction, 5e éd., Boston.  Smith et Alexander, 1988 : Douglas K. Smith et Robert C. Alexander, Fumbling the Future : How Xerox Invented, then Ignored, the First Personal Computer, New York.  Suchman, 2006 : Lucy Suchman, Human-Machine Reconfigurations : Plans and Situated Actions, Cambridge. 