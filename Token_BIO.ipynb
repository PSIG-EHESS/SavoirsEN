{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2601e355",
   "metadata": {},
   "source": [
    "# 1 - Step\n",
    "\n",
    "## import SpaCy\n",
    "## import all files\n",
    "## improving the tokenization process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d27ea00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy_bert/BNU_01_Didier_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_02_Colin_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_03_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_04_Gfrereis_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_05_Dege_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_06_Therstappen_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_07_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_08_PoncerGuedron_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_09_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_10_Bon_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_11_Bert_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_12_Bigg_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_13_Mathis_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_14_Canfora_a_voir_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_15_Mohnike_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_16_Grage_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/BNU_17_Ochsner_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_11_2018_Calame_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_11_2018_Dupont_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_11_2018_introduction_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_11_2018_Longhi_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_11_2018_Saint-Martin_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_11_2018_Wersinger_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_8_Buccheri_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_8_Caillaud_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_8_Davieau_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_8_Introduction_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_8_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/CMA_8_Mahieu_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_01_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_02_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_03_Fabiani_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_04_Dugast_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_06_Elman_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_07_Jacob_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_08_Glassner_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_09_Delatour_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_10_Herrou_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_11_Chatelain_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_12_Guerin_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_13_Durand_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_14_Icher_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_15_Stroumsa_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_16_KochPiettre_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_17_Poirel_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_18_Tillman_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_19_Faure_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_20_Houdart_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_21_Celenza_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSI_24_Mandressi_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_01_Jacob_Introduction_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_02_Jacob_LelogeMainPensee_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_03_Liberski_DevinsKasena_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_04_Icher_LesOutilsDuCompagnon_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_05_Samson_LaMainEtLoutil_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_06_Campos_GesteMusicalPiano_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_07_Brives_LobservationAuMicroscope_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_08_Fraenkel_LinsaisissableTableAEcrire_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_09_Icher_LetabliDuMenuisier_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_10_Schneider_LaTableDuLettreChinois_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_11_Chatelain_LesGardoiresDuLettre_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_12_BeaudoinLafon_TablesInformatiques_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_13_Jacob_ManipulerManier_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_14_Glassner_DissectionMe_sopotamie_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_15_Schnapp_TerrainAntiquaireArche_ologue_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_16_Lacour_AdministrationChosesNaturelles_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_17_Benazera_LaRechercheIntelligenceExtraterrestre_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_18_Mandressi_GestesFormesEcritureSavante_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_19_Ragazzoli_LireInscrireSurvivreEgypteAncienne_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_20_Jolly_NotesTerrainMarcelGriaule_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_21_DacosMounier_LesCarnetsDeRecherche_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_22_Bustarret_Coupercoller_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_23_Chatelain_RaisonsDecrire_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_26_Escande_LeGesteCalligraphiqueChine_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_27_Dejean_LaStructurationDocumentsElectroniques_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_28_Lardet_UsagesArchives_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_29_Revel_ChantdelaMemoire_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_30_Colas_RelectureCorrectionManuscritsIndiens_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_31_Dorival_Hexaples_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_32_Blair_TablesIndex_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_33_Berra_Thesaurus_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_34_Besse_NatureFormesProductivite_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_35_Zucker_Catasterismes_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_36_Jacob_Cartographie_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_37_Mandressi_ImagesMedicales_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_38_Houdart_ArchitectureTrompeLoeil_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_39-2_Galewicz_MemoireOubli_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_40_Guerin_Tablette_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_42_Jacob_Cheminements_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_43_Deleage_Amerindien_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_44_Mendelsohn_Maladie_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_45_Jensen_Savoir_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_46_Jacob_RaisonsGraphiques_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_47_Narcy_Particule_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_48_Lackner_Chine_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_49_Andler_Math_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_50_Fabiani_SituationsExtremes_text_BIO_conll_SpaCy_bert.tsv\n",
      "SpaCy_bert/LDSII_52_Kassow_OnegShabbes_text_BIO_conll_SpaCy_bert.tsv\n"
     ]
    }
   ],
   "source": [
    "# operation system\n",
    "import os\n",
    "# regular expression\n",
    "import re\n",
    "# retrives file support\n",
    "import glob\n",
    "# make a table\n",
    "import pandas as pd\n",
    "# regular expression\n",
    "import re\n",
    "\n",
    "# SpaCy NLP\n",
    "import spacy\n",
    "from spacy.training import offsets_to_biluo_tags\n",
    "from spacy.lang.fr import French\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load('fr_dep_news_trf')\n",
    "except OSError:\n",
    "    #print(\"Do you have the spacy module fr_core_news_sm installed? If not run 'python -m spacy download fr_core_news_sm'\")\n",
    "    \n",
    "    def custom_tokenize(text):\n",
    "        words = text.split('|')\n",
    "        return Doc(nlp.vocab, words=words)\n",
    "    nlp.tokenizer = custom_tokenize\n",
    "\n",
    "    # inform the path\n",
    "    for file_path in glob.iglob('tokenized_text/*.txt'): \n",
    "        #transform path into a readable file\n",
    "        f_name = (file_path)\n",
    "        #print(f_name)\n",
    "\n",
    "        # open the variable to be read and split into words\n",
    "        with open(f_name, 'r', encoding='utf8') as f:\n",
    "            # read and split into words to count word in file\n",
    "            #text = f.read()\n",
    "\n",
    "            words = f.read().replace('\\n', '|').replace('||','|').replace('||','|')\n",
    "            words = words[:-1] #remove last pipe\n",
    "            #print(words)\n",
    "\n",
    "            # apply SpaCy\n",
    "            doc = nlp(words)\n",
    "\n",
    "            entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "            tags = offsets_to_biluo_tags(doc, entities)\n",
    "\n",
    "            # directory out\n",
    "            output_dir = \"SpaCy_bert/\"\n",
    "            # new files out with original's name plus _text and its new format .txt\n",
    "            results_file = \"%s%s_SpaCy_bert.tsv\"%(output_dir, os.path.splitext(os.path.basename(f_name))[0])\n",
    "            print(results_file)\n",
    "\n",
    "\n",
    "            # save it as blabla_text.tok\n",
    "            count = 0\n",
    "            with open(results_file, 'w', encoding='utf8') as fpout: \n",
    "                for tok in words.split(\"|\"):\n",
    "                    tag = str(tags[count])\n",
    "                    fpout.write(str(tok)+\"\\t\"+tag+\"\\n\")\n",
    "                    count = count + 1\n",
    "                fpout.close()\n",
    "            #print(\"fini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0ad021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
