<text xml:id="text">
<front>

</front>
<div>
<p>Inventé il y a soixante ans, l’ordinateur est
        devenu personnel il y a vingt-cinq ans à peine, et sa mise en réseau
        généralisée, avec le Web, a commencé il y a quinze ans. Ces
        développements technologiques ont permis la création de dispositifs
        d’interaction rendant les ordinateurs accessibles aux
        non-spécialistes, tels que les notions désormais familières de
        fenêtre, d’icône, de menu, de document. Ils ont engendré des mutations
        profondes dans nos modes d’accès à l’information, dont les plus
        marquantes concernent le travail savant.</p>
<p>L’un des meilleurs exemples de ces mutations est
        sans doute l’évolution des pratiques de l’enseignement à l’école et à
        l’université : dématérialisation progressive des cahiers et des
        manuels scolaires, mise en ligne des cours et des travaux dirigés,
        généralisation des Environnements Numériques de Travail, mise en
        réseau des savoirs et des compétences à travers les outils
        d’intelligence collective, etc. Le monde de l’éducation,
        traditionnellement lent dans la mise en œuvre de nouvelles
        technologies, s’approprie d’autres façons d’apprendre, modifie le
        bagage intellectuel des élèves concernant les moyens et les méthodes
        d’accès à la connaissance et scelle ainsi la transition de la société
        industrielle vers la société de l’information.</p>
<p>L’objet de ce chapitre est d’examiner quelques
        étapes remarquables dans l’évolution des interfaces informatiques pour
        la manipulation et l’organisation d’informations complexes. Il vise
        notamment à identifier les concepts fondateurs qui se sont imposés
        dans les systèmes commerciaux d’aujourd’hui ainsi que les directions
        actuelles de recherche qui alimenteront les futurs dispositifs. La
        présentation, essentiellement chronologique, est articulée autour de
        cinq grands moments : la vision de <persname>Doug
        Engelbart</persname> du rôle des ordinateurs dans le développement de
        l’intelligence collective ; l’essor et la généralisation de
        l’informatique personnelle avec le Xerox Star puis le Macintosh ; la
        mise en réseau généralisée des informations et des services avec le
        Web ; les nouvelles formes d’interaction avec les surfaces tactiles de
        toutes tailles et les environnements augmentés, et, enfin, une sorte
        de retour vers le futur avec le papier interactif.</p>
<div>
          La vision de Doug
          Engelbart
          <p>Au moment de l’invention de l’ordinateur,
          <persname>Vannevar Bush</persname>, alors
          directeur du programme de recherche de l’armée américaine, publie un
          article décrivant le Memex, une machine électromécanique qui permet
          d’archiver des documents, de les lier entre eux et de les
          retrouver<note>
<p>
<hi>Bush</hi>, 1945</p>
</note>. Ce dispositif, considéré comme l’ancêtre des systèmes
          hypertexte, est qualifié par <persname>Bush</persname> de « Memetic
          Extender », ou extension mémorielle. Il s’inscrit dans la longue
          histoire des dispositifs inventés par l’homme pour développer ses
          capacités intellectuelles en externalisant dans des artefacts ou des
          machines certaines de ses fonctions cognitives, comme la
          mémoire.</p>
<p>Il est particulièrement intéressant de noter que
          le Memex se présente sous la forme d’un bureau abritant une
          mécanique complexe et offrant à l’utilisateur une interface
          constituée de dispositifs d’entrée (un clavier, à droite) et de
          sortie (trois écrans). Il est donc conçu pour remplacer un bureau
          traditionnel et s’intégrer ainsi naturellement aux flux et méthodes
          de travail en usage, augmentant les capacités de traitement de
          l’information de son utilisateur.</p>
<p>Cette idée d’amplification des capacités humaines
          est reprise et largement développée par <persname>Douglas
          Engelbart</persname>, qui publie en <date>1962</date> un article séminal<note>
<p>
<hi>Engelbart</hi>, 1962.</p>
</note> dans lequel il présente sa vision du rôle des systèmes
          informatiques pour « élever le niveau intellectuel collectif » grâce
          aux possibilités de traitement d’information et de collaboration
          qu’offrent les ordinateurs. La vision d’<persname>Engelbart</persname>
          est ambitieuse : face à la complexité croissante des problèmes que
          doit résoudre l’humanité, l’intelligence d’une seule personne ou
          celle d’un groupe ne sont plus suffisantes, non plus que
          l’« intelligence » d’une machine informatique. La seule façon de
          résoudre ces problèmes est d’augmenter l’intelligence collective
          grâce à des systèmes qui permettent aux humains de collaborer et
          d’exploiter les capacités des ordinateurs.</p>
<p>Le Memex ne sera jamais construit, mais <persname>Engelbart</persname> s’attelle à la
          construction de systèmes d’augmentation. Comme avec le Memex, il
          s’agit de donner une efficacité plus grande aux situations
          habituelles de travail telles les réunions en mettant à la
          disposition des utilisateurs des outils de partage et d’édition de
          documents, et des moyens de communication médiatisée permettant la
          collaboration à distance.</p>
<p>À la fin de <date>1968</date>, <persname>Engelbart</persname> fait une
          démonstration publique<note>
<p>
<hi>Engelbart</hi>, 1968.</p>
</note> de son système NLS (On-Line System) devant plus de mille
          personnes à <placename>San Francisco</placename>. NLS
          est un système hypertexte collaboratif couplé à un système de
          vidéoconférence. Des utilisateurs séparés de quarante-cinq
          kilomètres éditent sur un mode collaboratif des données organisées
          hiérarchiquement, comme une liste de commissions. Lorsqu’ils
          collaborent, ils peuvent se voir par vidéoconférence et utiliser des
          télépointeurs pour montrer des objets à l’écran.</p>
<p>L’interaction avec NLS est complexe, notamment à
          cause de l’utilisation du clavier à accords <hi>(<foreign>chord
          keyboard</foreign>)</hi>, qui permet de déclencher des commandes
          selon l’accord composé avec les doigts de la main gauche. Bien
          qu’<persname>Engelbart</persname> soit aussi
          l’inventeur de la souris, il a toujours été perplexe devant l’idée
          de systèmes conviviaux ou faciles d’utilisation. Il considère en
          effet que la facilité d’utilisation n’est pas un but en soi : à
          l’image du vélo qui nécessite un apprentissage plus long que le
          tricycle, mais qui est bien plus rapide, une interface adaptée aux
          capacités des utilisateurs mais requérant un apprentissage est plus
          efficace à long terme qu’une interface simpliste accessible à tout
          le monde.</p>
<p>Cette philosophie est au cœur de ce qu’<persname>Engelbart</persname> appelle le <hi>« <foreign>bootstrap</foreign> »</hi>,
          c’est-à-dire la capacité d’utiliser les outils non seulement pour
          résoudre les problèmes du moment, mais aussi pour améliorer les
          outils eux-mêmes et, plus généralement, « améliorer le processus
          d’amélioration ». Elle tranche nettement avec les développements de
          ce qui deviendra la bureautique, qui met dans les mains des
          utilisateurs des outils souvent limités et non susceptibles d’être
          améliorés par ces mêmes utilisateurs.</p>
<p>Aussi la vision d’<persname>Engelbart</persname>
          est-elle loin d’être réalisée encore aujourd’hui (en <date>2010</date>), malgré l’augmentation massive
          de la puissance des ordinateurs et des réseaux. De nombreuses
          fonctionnalités de NLS (renommé Augment lorsque <persname>Engelbart</persname> quitte le SRI
          en <date>1978</date>) ne sont toujours pas
          disponibles commercialement, en particulier en ce qui concerne les
          outils de collaboration. L’avènement de l’informatique dite
          personnelle est d’ailleurs bien la preuve que la vision d’<persname>Engelbart</persname> de systèmes
          dédiés à la collaboration est restée largement ignorée.
          L’explication en est peut-être que, avec le Xerox Star et plus tard
          le Macintosh, décrits ci-dessous, l’informatique s’est intéressée à
          des catégories d’utilisateurs différentes de celles visées par
          <persname>Engelbart</persname> : les <hi>« <foreign>knowledge
          workers</foreign> » </hi>pour NLS, les secrétaires pour le Star, le
          grand public pour le Macintosh. Malgré la puissance potentielle du
          processus de <hi>« <foreign>bootstrap</foreign> »</hi>, le gain immédiat que
          peuvent apporter des systèmes demandant peu ou pas d’apprentissage
          est souvent perçu comme un avantage par rapport à des systèmes plus
          puissants mais demandant un investissement plus important. Il n’en
          reste pas moins qu’Engelbart est le premier à s’être intéressé à
          l’évolution concrète des pratiques du travail intellectuel grâce à
          l’ordinateur et à avoir réalisé des prototypes fonctionnels. Et si
          sa vision d’une amplification de l’intellect humain reste largement
          à réaliser, elle sous-tend néanmoins toute l’évolution de
          l’informatique interactive des cinquante dernières années.</p>
<figure>
<graphic></graphic>
            Bill English utilisant la souris (main
            droite) et le clavier à accords (main gauche).
          </figure>
</div>
<div>
          Le Xerox Star et le début de
          l’informatique personnelle
          <p>En <date>1970</date>,
          grâce aux importants bénéfices obtenus avec ses brevets sur la
          xérographie, la société Xerox crée un laboratoire de recherche à
          <placename>Palo Alto</placename>, le PARC
          (Palo Alto Research Center). Xerox veut non seulement poursuivre le
          développement de sa technologie, mais aussi anticiper l’expiration
          des brevets et se lancer dans les systèmes bureautiques. De fait, le
          marché des photocopieurs lui donne un accès privilégié au secteur
          tertiaire. Pendant plus de trente ans, le Xerox PARC sera le théâtre
          d’un nombre spectaculaire d’inventions qui ont marqué l’histoire de
          l’informatique, à tel point que le slogan favori des chercheurs du
          PARC, attribué à <persname>Alan Kay</persname>, l’un de ses
          fondateurs, est : « La meilleure façon de prédire le futur, c’est de
          l’inventer. »</p>
<p>Le Xerox Star est la première station de travail
          graphique commercialisée de l’histoire<note>
<p>
<hi>Smith</hi>
<hi>et
              al.</hi>, 1982 ; <hi>Johnson</hi>
<hi>et al.</hi>, 1989.</p>
</note>. Elle est le résultat d’un programme de recherche de près
          de dix ans qui a vu le développement de multiples prototypes, dont
          l’Alto, et l’invention de tous les concepts de l’informatique
          interactive moderne. <persname>Alan Kay</persname>, considéré
          comme le père de l’informatique personnelle, a largement influencé
          ces travaux. Sa vision n’est pas très éloignée de celle d’<persname>Engelbart</persname> : il s’agit de
          fournir à l’utilisateur non pas des applications préprogrammées,
          mais un ensemble d’outils pour construire son propre environnement.
          Cette vision sera à la base du langage et de l’environnement de
          programmation graphique Smalltalk, que <persname>Kay</persname>
          continue de développer aujourd’hui sous le nom de Squeak. Pour le
          Xerox Star cependant, qui n’est plus un projet de recherche mais un
          projet commercial, cet objectif sera largement laissé de côté. La
          cible du Star est la secrétaire de direction, qui doit manipuler un
          grand nombre de documents, les compiler pour son patron, les
          transmettre aux autres employés, etc. Il s’agit d’un travail de
          bureau avec une forte valeur ajoutée. Le Xerox Star présente donc
          une interface métaphorique dans usuels du travail de bureau sont
          représentés à l’écran : casiers pour le courrier, dossiers pour
          ranger les documents, corbeille à papier, calendrier, etc. (voir
          <ref>http://visite.imusee.info/Renaissance_Files/droppedImage_1.png</ref>).</p>
<p>Les documents eux-mêmes sont présentés dans des
          fenêtres que l’on peut manipuler comme les feuilles de papier sur un
          bureau. Ces documents peuvent contenir du texte, des images, des
          tableaux, des graphiques et ils apparaissent à l’écran de façon
          identique à leur version imprimée : on parle de principe WYSIWYG <hi>(What You See Is What You Get)</hi> – « ce que vous
          voyez est ce que vous avez ».</p>
<p>Les icônes, les fenêtres et le contenu des
          documents peuvent être manipulés de façon uniforme grâce à une
          souris qui permet de les désigner à l’écran et des touches de
          fonction aisément accessibles de part et d’autre de la partie
          alphabétique du clavier. Le Star s’inspire ainsi de l’interface
          bimanuelle de NLS, en remplaçant le clavier à accords par des
          touches de fonction. La force de l’interface du Star est de
          permettre de réaliser des manipulations complexes à partir d’un
          petit nombre de fonctions, accessibles par le clavier pour la
          plupart : Déplacer, Copier, Détruire, Ouvrir, Chercher, Annuler,
          Propriétés, Caractères, etc. Ainsi la métaphore opère-t-elle non
          seulement sur les objets présentés, mais également sur la façon de
          les manipuler. Par exemple, la plupart des objets ont des
          propriétés, qui dépendent du type de l’objet. Une seule fonction,
          « Propriétés », affiche une feuille de propriétés spécifique à
          l’objet affiché sous le curseur de la souris.</p>
<p>Comme dans toutes les interfaces réussies,
          l’important est ce qui ne se voit pas, c’est-à-dire ce que les
          concepteurs ont réussi à dissimuler ou à rendre « transparent »,
          intuitif pour l’utilisateur. Ainsi, l’interface du Star est fondée
          sur la notion de document, et il n’y a pas à proprement parler de
          notion d’application. Comme les documents du monde réel, les
          documents du Star peuvent contenir du texte, des formules
          mathématiques, des tableaux, des graphiques. Ils sont créés à partir
          de modèles, et il est possible d’insérer tout type de contenu
          n’importe où dans un document. On peut coupler un graphique à un
          tableau de telle sorte que le graphique soit mis à jour
          immédiatement lorsque le tableau est modifié. La métaphore du Star
          n’est donc pas une copie du monde réel : elle s’inspire de celui-ci
          pour le prolonger de façon cohérente et aisément compréhensible par
          l’utilisateur.</p>
<p>D’autre part le Star est fondamentalement une
          machine ouverte au réseau informatique, à tel point qu’il est
          pratiquement invisible pour l’utilisateur. Celui-ci peut configurer
          son environnement en parcourant un catalogue de ressources
          accessibles à travers le réseau local : serveurs de fichiers,
          imprimantes, etc. Il installe ces ressources sur le bureau
          électronique, où elles apparaissent sous forme d’icônes et restent
          accessibles d’une session à l’autre. Ainsi la différence entre
          ressource locale et ressource distante est-elle invisible. Là aussi,
          un effort particulier est fait pour que la technologie soit au
          service de la cohérence du système du point de vue de
          l’utilisateur.</p>
<p>Tous les concepts des interfaces modernes sont
          présents dans le Star. À vrai dire, le Star est encore en avance par
          rapport aux interfaces actuelles : la transparence du réseau,
          l’environnement centré sur les documents, l’utilisation d’un petit
          nombre de commandes qui s’appliquent à un grand nombre de contextes
          sont autant de caractéristiques du Star qui ne sont toujours pas
          présentes dans les environnements actuels. Pourtant le Star fut un
          échec commercial : système trop cher, cible marketing mal évaluée et
          surtout incapacité de Xerox à sortir de son marché historique des
          photocopieurs.</p>
</div>
<div>
          Le Macintosh et les limites
          de la métaphore du bureau
          <p>Après l’échec du Star, le succès du Macintosh
          d’Apple marque le point de départ de l’informatique personnelle pour
          le grand public. À première vue, l’interface du Macintosh est
          largement inspirée du Star : des fenêtres qui affichent des
          documents, des icônes sur le bureau virtuel, une souris, des
          commandes accessibles dans des menus et, très rapidement, la
          connectivité au réseau local.</p>
<p>Pourtant, le concept est, dès le départ,
          différent<note>
<p>
<hi>Raskin</hi>, 2000.</p>
</note>, et une grande partie de l’interface du Macintosh est
          dérivée du Lisa<note>
<p>
<hi>Perkins</hi>
<hi> et
              al.</hi>, 1997.</p>
</note>. Ainsi, alors que le Star utilise peu les menus en se
          concentrant sur les fonctions génériques accessibles au clavier, le
          Macintosh reprend la barre de menus du Lisa qui offre, en haut de
          l’écran, un accès à toutes les commandes du logiciel. D’autre part,
          tandis que le Star est centré sur les documents, le Macintosh est
          centré sur la notion d’application, dédiée à la manipulation d’un
          type de document. Certes, il est possible de copier les éléments
          d’un document dans un document d’un autre type, mais cette copie
          n’est pas éditable dans le document où elle est collée : il faut
          revenir au document initial et refaire l’opération de copier-coller.
          Enfin, la transparence au réseau n’est pas vraiment au
          rendez-vous.</p>
<p>D’un autre côté, alors que le Star était une
          machine fermée, pour laquelle seul Xerox pouvait développer du
          logiciel, le Macintosh est une machine ouverte aux développeurs
          extérieurs. C’est probablement la raison de son succès (et de celui
          du PC Windows) : tandis que le Star est dédié à un usage unique, le
          Macintosh dispose de logiciels couvrant une gamme d’activités de
          plus en plus large. Il est particulièrement apprécié dans les
          milieux de la production audiovisuelle, des médias, de l’édition et,
          de façon générale, dans les domaines artistiques et culturels. Le
          design du matériel et du logiciel montre en effet un goût du détail,
          une esthétique, une flexibilité, mais aussi une performance et un
          concept tout-en-un qui sont appréciés de ces publics.</p>
<p>Malgré des évolutions régulières, l’interface du
          Macintosh n’a pratiquement pas changé depuis l’origine, en tout cas
          au niveau de ses principes. Les documents sont organisés en dossiers
          dans une structure strictement hiérarchique qui oblige l’utilisateur
          à imaginer un système de classement rigoureux. L’interaction est une
          évolution des principes du Star : l’utilisateur désigne le ou les
          objets d’intérêt avec la souris, définissant ainsi une « sélection »
          d’objets ; il active ensuite une commande par l’intermédiaire des
          menus déroulants de la barre de menus, d’un menu contextuel, d’une
          palette ou d’un raccourci clavier. Éventuellement, une boîte de
          dialogue apparaît pour spécifier des paramètres supplémentaires de
          la commande. Enfin la commande est appliquée à la sélection,
          modifiant éventuellement celle-ci. Une autre forme d’interaction est
          aussi largement utilisée : le <hi>« <foreign>drag-and-drop</foreign> »</hi> ou « cliquer-tirer »,
          qui consiste à prendre un objet et le déplacer au-dessus d’un autre
          objet, ce qui a pour effet de déclencher une commande dépendant de
          l’objet déplacé et de la destination choisie. Cette commande est
          souvent une opération de déplacement ou de copie de l’objet source
          vers l’objet destination et s’inspire de notre interaction dans le
          monde physique : prendre un objet pour le poser ailleurs.</p>
<p>De façon générale, les interfaces graphiques
          popularisées par le Macintosh et reprises depuis par Microsoft
          Windows et Linux ont atteint un degré important de stabilité et de
          similarité. L’avantage indéniable est que tout utilisateur peut
          aisément s’approprier un nouveau logiciel, voire changer de
          plate-forme. L’inconvénient est que cette standardisation limite
          l’innovation, alors même qu’il existe de nouvelles méthodes
          d’interaction plus efficaces et que la métaphore du bureau montre
          ses limites<note>
<p>
<hi>Beaudouin-Lafon</hi>, 2000.</p>
</note>.</p>
<p>Ainsi, la généralisation des palettes et des
          menus multiplie le nombre de commandes disponibles, tandis que le
          Xerox Star avait adopté une approche minimaliste, grâce à
          l’utilisation de commandes génériques. Certaines techniques
          d’interaction comme les menus circulaires <hi>(<foreign>pie menus</foreign>)</hi>
          inventés en <date>1986</date> par <persname>Don Hopkins</persname>
<note>
<p>
<hi>Callahan</hi>
<hi> et
              al.</hi>, 1988.</p>
</note> et améliorés en <date>1993</date>
          par <persname>Gordon Kurtenbach</persname>
<note>
<p>
<hi>Kurten-Bach</hi> et <hi>Buxton</hi>, 1993.</p>
</note> peuvent accélérer la sélection dans un menu d’un facteur
          trois. De façon similaire les <hi>« <foreign>toolglasses</foreign>
</hi>
<note>
<p>
<hi>Bier</hi>
<hi>et al.</hi>,
              1993.</p>
</note>
<hi> »</hi>, des palettes semi-transparentes
          manipulées par la main non dominante, peuvent améliorer la
          performance de l’interaction de 40 % par rapport aux palettes
          classiques.</p>
<figure>
<graphic></graphic>
            Les nombreuses palettes de l’interface de
            Microsoft Word sur le Macintosh en 2001.
          </figure>
<p>Par ailleurs, la quantité de documents archivés
          par les utilisateurs augmente de façon exponentielle, et il devient
          impossible de les gérer avec un simple système de dossiers
          hiérarchiques. Beaucoup d’utilisateurs s’en remettent au moteur de
          recherche qui équipe désormais ces environnements (<foreign>Spotlight</foreign> sur le Macintosh) pour retrouver
          un document non pas en allant le chercher là où il est, mais en
          déléguant la recherche à l’ordinateur. Cette approche est très
          efficace lorsqu’elle rapporte le document recherché, mais très
          frustrante lorsque l’utilisateur sait que le document existe mais
          qu’il ne peut le trouver. La recherche d’un document devient alors
          une tâche à part entière, qui souvent interrompt la tâche principale
          et en fait perdre le fil.</p>
<p>Enfin, le nombre d’applications et de fenêtres
          présentes simultanément à l’écran augmente alors que la taille des
          écrans reste relativement stable, provoquant un encombrement de
          l’espace disponible. Les « Spaces » et la technique « Exposé » du
          Macintosh permettent de pallier ces problèmes en répartissant les
          fenêtres sur plusieurs bureaux virtuels et en affichant des
          miniatures des fenêtres, mais là encore on arrive rapidement aux
          limites de la mémoire à court terme lorsqu’une tâche est interrompue
          par de multiples manipulations de fenêtres. D’autres techniques
          telles que celles du logiciel de fenêtrage Metisse<note>
<p>
<hi>Chapus</hi> et <hi>Roussel</hi>, 2005.</p>
</note> permettent de manipuler les fenêtres comme des feuilles de
          papier réelles, par exemple en les roulant pour faire apparaître ce
          qui est dessous, évitant ainsi de nombreuses manipulations.</p>
<p>En vingt ans, l’écran de l’ordinateur, qui
          délimitait jadis un monde relativement petit et dont l’utilisateur
          pouvait conserver une image mentale précise, est devenu une petite
          fenêtre sur un vaste entrepôt où s’accumulent des documents de
          toutes sortes. L’ordinateur ne sert plus seulement à des tâches
          bureautiques de fabrication de documents, c’est aussi un centre de
          communication (courrier électronique, messageries instantanées,
          etc.), un guichet pour tous les services de commerce en ligne, un
          centre de stockage multimédia pour les photos, les films, la
          musique, etc. La métaphore du bureau n’a jamais été conçue pour des
          usages aussi variés ni pour passer à l’échelle de dizaines ou
          centaines de milliers de documents. De toute évidence, de nouveaux
          paradigmes sont nécessaires pour apporter des solutions nouvelles à
          ces problèmes et redonner le contrôle à l’utilisateur qui se sent de
          plus en plus dépassé par la complexité qui lui est imposée.</p>
<figure>
<graphic></graphic>
            À gauche : un menu circulaire permet une
            sélection rapide par un geste directionnel ; à droite : une
            « toolglass » ou palette semi-transparente, manipulée avec la main
            non dominante, permet de colorer un dessin en cliquant à travers
            la palette sur la zone à colorier.
          </figure>
</div>
<div>
          Le World Wide Web et
          l’information répartie
          <p>Ces problèmes sont d’autant plus criants que les
          documents désormais à portée de main ne sont plus seulement « dans »
          l’ordinateur, mais n’importe où dans le monde, accessibles à travers
          le Web. Le Web a radicalement modifié les pratiques de travail en
          remplaçant de nombreux déplacements physiques dans les
          bibliothèques, les librairies, les administrations et les commerces
          par des interactions avec des machines à travers les navigateurs
          Web. Cette commodité d’accès a cependant un coût : elle nous prive
          des interactions avec les interlocuteurs humains dans ces différents
          lieux, de l’accès à leurs savoirs et compétences. Même si ceux-ci
          sont en partie compensés par les moyens de communication nouveaux
          que le Web et Internet en général mettent à notre disposition
          (forums de discussion, listes de distribution, sites sociaux, etc.),
          accéder aux milliards de documents disponibles sur le Web à travers
          les fenêtres d’un navigateur pose de nombreux problèmes.</p>
<p>Un premier ensemble de problèmes est lié à la
          difficulté de s’approprier les documents du Web comme on s’approprie
          des ouvrages ou documents que l’on achète dans une librairie. Le
          problème principal est la fluidité du Web : un document peut changer
          d’adresse, son contenu peut évoluer, il peut être temporairement
          inaccessible, etc. Il s’ensuit que les trois opérations les plus
          fréquentes sur un document dont on n’est pas l’auteur, à savoir
          l’archiver, l’annoter et le citer, ne sont pas réalisables
          simplement avec les documents extraits du Web. Pour archiver un
          document, on peut créer un marque-page ou un favori, mais les outils
          de rangement et de recherche offerts par les navigateurs sont
          limités. En conséquence, on préfère souvent télécharger le document
          pour le ranger dans son propre système de fichiers, au risque de
          perdre trace de son origine. Pour annoter un document, il faut
          également le télécharger et annoter sa copie locale. Pour le citer
          enfin, il faut copier son contenu et perdre trace de l’origine de la
          citation.</p>
<p>Pourtant, certaines solutions ont été imaginées
          pour permettre ces usages de façon plus naturelle. Dans la première
          version du navigateur Mosaic, il était possible d’annoter les pages
          Web à l’intérieur du navigateur. Les annotations étaient stockées
          sur la machine de l’utilisateur et rappelées lorsque la page était à
          nouveau consultée. Le seul problème de cette approche est que
          lorsque la page change, les annotations peuvent devenir obsolètes.
          Ce problème pourrait être résolu si l’utilisateur pouvait
          enregistrer une copie locale de la page et avoir la possibilité de
          mettre à jour ses annotations lorsque la page change.</p>
<p>Concernant la citation, <persname>Ted Nelson</persname>,
          l’inventeur du terme « hypertexte », a proposé dès les <date>années 1970</date>, sous le nom
          de Xanadu, le concept d’un système mondial pour la publication en
          réseau de documents<note>
<p>
<hi>Nelson</hi>, 1992.</p>
</note>. Ce système est fondé sur un modèle plus riche et plus
          complexe que celui du Web actuel : il permet notamment de parcourir
          les liens « à l’envers », afin de retrouver directement toutes les
          pages qui citent une page donnée. Xanadu implémente aussi le concept
          de « transclusion », qui permet d’inclure le contenu d’un document
          source sans le copier, et prévoit même un système de redevance pour
          l’accès à de tels contenus.</p>
<p>Une deuxième catégorie de problèmes liés à
          l’usage du Web est la publication des documents. Alors que <persname>Tim
          Berners-Lee</persname> envisageait un système où tout le monde
          pouvait être lecteur mais aussi auteur<note>
<p>
<hi>Berners-Lee</hi>
<hi>et
              al.</hi>, 1994.</p>
</note>, la réalité actuelle est qu’il est bien plus facile d’être
          lecteur qu’auteur. Pourtant, la version originale du navigateur Web,
          créée par <persname>Berners-Lee</persname> pour la
          plate-forme NeXT, intégrait des fonctions d’édition permettant de
          modifier une page comme on modifie un document texte, depuis le
          navigateur, et de mettre à jour celle-ci sur le serveur d’origine, à
          condition bien sûr d’avoir les droits d’accès nécessaires.</p>
<p>Comme ces facilités d’édition et de publication
          ne sont pas présentes dans les navigateurs, elles sont
          progressivement apparues à l’intérieur des pages Web elles-mêmes.
          C’est par exemple le cas dans les logiciels de blog ou les sites de
          réseaux sociaux qui permettent de créer le contenu par
          l’intermédiaire de formulaires. La conséquence est que le Web
          contient désormais non seulement des documents, mais également des
          applications réelles qui reproduisent les interfaces auxquelles nous
          sommes habitués sur nos environnements de bureau. À titre d’exemple,
          l’application Web <ref>
<hi>280slides.com</hi>
</ref> reproduit dans un navigateur l’interface de l’application
          de création de présentations Keynote d’Apple.</p>
<p>L’évolution du Web d’une plate-forme de
          publication de documents vers une plate-forme de distribution
          d’applications conduit à encourager les utilisateurs à déposer leurs
          documents sur les sites qui hébergent ces applications, et non plus
          sur le disque dur de leur ordinateur personnel : le courrier
          électronique sur GMail, les documents sur Google Docs, les photos
          sur Flickr, les vidéos sur YouTube, etc. Chacune de ces applications
          gère son propre espace de stockage, à travers sa propre interface et
          sans possibilité d’interopérabilité simple avec le bureau virtuel
          traditionnel, ses dossiers et ses documents.</p>
<p>Cette évolution tend <hi>in fine
          </hi>à renverser la logique du Web : d’un côté, l’utilisateur
          récupère les documents qu’il a consultés sur le Web pour être sûr de
          ne pas les perdre, de l’autre, il cède la gestion de ses propres
          documents à des services tiers, au risque d’ailleurs d’en perdre la
          propriété ! De toute évidence, le décalage croissant entre ces
          nouvelles pratiques et leur équivalent dans le monde physique est
          une source de difficulté pour les utilisateurs, qui passent une
          proportion croissante de leur temps à des tâches de transfert, de
          recherche et d’organisation de leurs documents. C’est pour pallier
          ces problèmes que de nouvelles approches sont étudiées dans les
          laboratoires de recherche.</p>
</div>
<div>
          Les environnements augmentés
          et les surfaces tactiles
          <p>En <date>1991</date>,
          <persname>Mark Weiser</persname> présente dans un
          article séminal sa vision de l’informatique du <date>
<hi>xxi</hi>
<hi>e</hi> siècle</date>
<note>
<p>
<hi>Weiser</hi>, 1991.</p>
</note> : <foreign>Ubiquitous Computing</foreign>,
          ou l’accès à l’information en ligne omniprésent dans l’environnement
          physique, grâce à des ordinateurs et des écrans de toutes tailles.
          Cette vision préfigure clairement l’avènement des smartphones, PDAs,
          TabletPC et autres NetBooks, mais elle contient l’idée d’une forte
          intégration entre ces différents dispositifs qui est loin d’être
          réalisée aujourd’hui. L’objectif de <persname>Weiser</persname> est en effet de pouvoir passer de
          façon fluide d’un support à l’autre selon le contexte d’utilisation,
          de faire en sorte que les documents suivent les utilisateurs là où
          ils en ont besoin et que les ressources soient aisément partagées
          entre les participants. Cela nécessite une révision profonde des
          infrastructures actuelles, qui tendent à balkaniser nos
          environnements informatiques en produits propriétaires
          incompatibles.</p>
<p>La vision de <persname>Weiser</persname> trouve un prolongement naturel dans
          la notion de réalité augmentée<note>
<p>
<hi>Wellner</hi>
<hi> et
              al.</hi>, 1993.</p>
</note>, qui a pour but d’intégrer l’information directement au
          sein des objets physiques usuels, brouillant ainsi les frontières
          entre mondes physique et informatique, afin de mieux tirer parti des
          savoir-faire des utilisateurs. Ainsi, le Digital Desk<note>
<p>
<hi>Wellner</hi>, 1993.</p>
</note> de <persname>Pierre Wellner</persname>
          augmente le bureau traditionnel et les objets posés dessus. Grâce à
          un projecteur et à une caméra montés au-dessus du bureau,
          l’ordinateur peut suivre les manipulations d’objets physiques posés
          sur le bureau, par exemple les feuilles de papier, et projeter des
          informations ou des applications, comme une calculette, que l’on
          peut manipuler à même le bureau.</p>
<p>Que ce soit l’Ubicomp ou la réalité augmentée,
          l’interaction repose largement sur l’utilisation de gestes familiers
          sur des surfaces interactives diverses ou dans l’espace<note>
<p>
<hi>Bolt</hi>, 1980.</p>
</note>. L’ordinateur classique avec son clavier, son écran et sa
          souris disparaît au profit de dispositifs mieux intégrés à
          l’environnement physique et capables d’une certaine perception de
          cet environnement afin de faciliter les activités de l’utilisateur.
          Par exemple, un ordinateur portable peut reconnaître la présence
          d’un projecteur dans une pièce et offrir à l’utilisateur de s’y
          connecter sans qu’il ait besoin de réaliser une connexion physique
          ni de manipuler une télécommande.</p>
<p>La plupart de ces nouveaux dispositifs reposent
          sur l’utilisation d’interfaces dites gestuelles, qui capturent les
          mouvements des doigts ou d’objets au contact d’une surface
          interactive. Cette interaction gestuelle est par nature plus riche
          que l’interaction à la souris qui ne traite que des positions
          discrètes : avec l’interaction gestuelle, il est possible de
          reconnaître des tracés ou des gestes, et l’interaction peut se faire
          avec plusieurs points de contact, comme cela a été popularisé
          depuis <date>2007</date> avec l’iPhone puis
          l’iPad d’Apple. Mais l’interaction gestuelle pose le problème de
          l’invisibilité <hi>a priori </hi>du vocabulaire
          gestuel, au contraire d’un système de menu qui peut être parcouru
          par l’utilisateur. Des techniques comme OctoPocus<note>
<p>
<hi>Bau</hi> et <hi>Mackay</hi>, 2008.</p>
</note> permettent cependant de résoudre ce problème tout en
          améliorant le taux de reconnaissance du système.</p>
<figure>
<graphic></graphic>
            L’iPad d’Apple permet une interaction
            gestuelle avec plusieurs points de contact.
          </figure>
<p>L’interaction gestuelle est également très
          adaptée à d’autres surfaces comme les tables interactives ou les
          murs interactifs. Les tables offrent l’avantage d’une situation de
          travail habituelle et invitent à la collaboration. Selon la
          technologie utilisée, elles peuvent également reconnaître la
          présence d’objets physiques et encourager ainsi une interaction dite
          tangible, où des objets physiques représentent des objets
          informatiques. Par exemple, un téléphone posé sur la table peut être
          reconnu et donner accès à son répertoire, tandis qu’un appareil
          photo permettra de visualiser directement les photos qu’il
          contient.</p>
<p>Dans le cas du mur interactif, on revient à une
          surface verticale. Sa taille et sa résolution permettent toutefois
          des usages impossibles avec les écrans de nos ordinateurs actuels.
          Ainsi le mur d’écran de la plate-forme WILD, installée au
          Laboratoire de recherche en informatique à Orsay, permet-il
          d’afficher 131 millions de pixels (20 480 × 6 400) sur une surface
          de 5,50 m × 1,80 m. Comme la table, le mur invite au travail
          collaboratif : il permet l’accès immédiat à un grand nombre de
          documents, tout comme il permet de passer d’une vue d’ensemble à une
          vue détaillée simplement en se déplaçant physiquement, sans
          manipulation d’une barre de défilement ou d’une roulette de
          souris.</p>
<figure>
<graphic></graphic>
            Le mur haute résolution de la plateforme
            WILD permet de manipuler des documents complexes en très haute
            résolution.
          </figure>
<p>Au-delà de l’intérêt de chacun de ces
          dispositifs, c’est leur combinaison qui permet d’envisager les
          usages les plus riches et les plus novateurs. En combinant une table
          et un mur interactifs, on pourra rechercher les documents d’intérêt
          sur la table et les afficher sur le mur, ou l’inverse. En munissant
          les utilisateurs de dispositifs portables et en suivant leur
          position dans l’espace, il sera possible de glisser des données
          présentes sur la table vers le dispositif portable, de se déplacer
          vers le mur et de les déposer à l’endroit de son choix.</p>
<p>À l’inverse de la réalité virtuelle qui enferme
          les utilisateurs dans un univers déconnecté du monde physique, la
          réalité augmentée et les approches Ubicomp tirent parti du monde
          physique et l’augmentent de capacités de traitement de
          l’information. Ces approches répondent finalement à la vision
          d’<persname>Engelbart</persname> : fournir des
          outils que les utilisateurs peuvent s’approprier pour améliorer leur
          propre processus d’augmentation. Alors que la métaphore du bureau
          créait une sorte de réalité virtuelle, accessible uniquement du bout
          du curseur de la souris ou des touches du clavier, ces nouvelles
          approches rendent l’information plus tangible, plus matérielle, plus
          concrète. Une étape supplémentaire dans cette direction est en train
          d’être franchie avec l’avènement du papier interactif.</p>
</div>
<div>
          Retour vers le futur : le
          papier interactif
          <p>S’il est un objet physique qui est au cœur des
          activités savantes, c’est bien le papier. Curieusement, toute
          l’histoire de l’informatique interactive a traité le papier comme un
          périphérique (on le numérise en entrée, on imprime dessus en
          sortie), et les tentatives pour s’en débarasser ont été vaines<note>
<p>
<hi>Sellen</hi> et <hi>Harper</hi>, 2001.</p>
</note>. Les propriétés du papier sont en effet remarquables : il
          est peu cher, robuste, flexible, de très haute résolution et il ne
          tombe pas en panne. Il fait partie de notre vie, du livre de La
          Pléiade à la nappe de restaurant en passant par les magazines,
          livres, notices, cahiers, carnets, feuilles volantes, cartes et
          Post-it qui prennent part à la moindre de nos activités
          quotidiennes.</p>
<p>Diverses technologies sont en passe de rendre au
          papier sa juste place dans notre vie numérique. La première richesse
          du papier est qu’il est possible d’écrire librement dessus et de
          conserver ce qui y est écrit. La technologie de la société Anoto,
          commercialisée notamment par Logitech, Nokia et Livescribe, permet
          de capter avec grande précision ce que l’on écrit sur un papier
          spécial avec un stylo adapté : le papier contient une fine grille de
          points, différente sur chaque page, et le stylo repère la position
          de la pointe sur la grille de points grâce à une micro-caméra. Les
          données enregistrées peuvent ensuite être transmises et traitées sur
          un ordinateur.</p>
<p>Dans le cas du stylo Livescribe, il est possible
          de télécharger des mini-applications dans le stylo lui-même. Par
          exemple, une application « calculette » reconnaît le tracé des
          chiffres et des quatre opérations. Lorsque l’on écrit « 2 + 3 = »,
          le stylo affiche le résultat dès que le signe « égale » est tracé.
          Le stylo peut également enregistrer le son ambiant, qui est
          synchronisé avec les données écrites : en tapant un mot, le stylo
          rejoue le son enregistré au moment où le mot était écrit. On imagine
          aisément l’intérêt de ce dispositif, par exemple pour annoter des
          documents de façon écrite ou orale et pour conserver ou transmettre
          les annotations (la grille de points peut être ajoutée lors de
          l’impression de n’importe quel document).</p>
<p>Une autre forme de papier interactif est issue
          des travaux de <persname>Nick Sheridon</persname> à
          Xerox PARC dans les <date>années 1970</date> : il s’agit d’un film plastique un
          peu plus épais que du papier, renfermant des billes bicolores, qui
          peut enregistrer et afficher une image indéfiniment, sans consommer
          d’énergie. Il s’agit en quelque sorte d’une feuille qui peut être
          effacée et récrite à l’infini. Des technologies proches sont
          utilisées aujourd’hui dans certains lecteurs de livres électroniques
          tels que le Reader de Sony et le Kindle d’Amazon, mais il n’existe
          pas encore de produit commercial permettant d’interagir directement
          avec ces supports.</p>
<p>
<persname>Wendy Mackay</persname> travaille
          depuis longtemps sur le papier interactif ; elle a créé plusieurs
          prototypes destinés notamment aux chercheurs en biologie qui
          consignent leurs recherches dans un cahier de laboratoire. Les
          chercheurs sont attachés au cahier de papier, qui ne peut être
          complètement informatisé car ils y collent des échantillons
          biologiques, des résultats imprimés par des appareils de mesures,
          etc. Dans l’un des prototypes, le A-book<note>
<p>
<hi>Mackay</hi>
<hi> et
              al.</hi>, 2002.</p>
</note>, un écran portable est utilisé comme une lentille magique
          pour interagir avec le contenu du cahier : l’écran affiche le
          contenu de la page sur laquelle il se trouve, donnant l’illusion
          d’un écran transparent. L’utilisateur peut alors cliquer, par
          exemple, sur un mot qui est reconnu comme une procédure, et l’écran
          indique la page où la procédure est décrite. D’autres prototypes
          utilisent la technologie Anoto pour établir aisément des liens entre
          les données consignées dans le cahier et des données en ligne, comme
          les résultats des logiciels d’analyse du génome.</p>
<p>Grâce au papier interactif, on peut s’attendre à
          franchir une nouvelle étape dans la meilleure intégration entre les
          mondes physique et électronique. Comme l’évoque <persname>Engelbart</persname> et comme le
          souligne <persname>Mackay</persname>
<note>
<p>
<hi>Mackay</hi>, 2000.</p>
</note>, ces technologies sont susceptibles de co-adaptation par
          les utilisateurs : alors qu’elles offrent à ces derniers des
          possibilités nouvelles, ils se les approprient également de façon
          inattendue grâce à leur flexibilité. Ces appropriations créent de
          nouveaux usages et, à leur tour, de nouveaux détournements.</p>
<p>Les technologies interactives sont les plus
          puissantes lorsqu’elles ménagent des espaces pour la coadaptation,
          lorsqu’elles encouragent et facilitent le <hi>« <foreign>bootstrap</foreign> »</hi>.
          Avant les interfaces graphiques, les interfaces à ligne de commande
          tiraient leur puissance des langages utilisés, mais elles n’étaient
          pas accessibles au grand public. Les interfaces graphiques et la
          métaphore du bureau ont permis une large appropriation, au prix
          toutefois d’une puissance d’expression plus limitée, qui se traduit
          par de nombreuses manipulations fastidieuses et répétitives. Les
          nouvelles interfaces visent à mieux exploiter les capacités
          sensorimotrices de l’être humain afin que celui-ci puisse à son tour
          mieux exploiter les capacités de calcul et de stockage des
          ordinateurs.</p>
<p>Alors que la transition vers les interfaces
          graphiques a été brutale, il est peu probable qu’une nouvelle
          rupture de ce type se produise. En effet ces interfaces sont
          aujourd’hui trop répandues, et notre vie dépend tellement d’elles
          que l’on ne peut pas les remplacer du jour au lendemain. La future
          révolution se fera donc en douceur : elle a déjà été abordée par les
          smartphones tels que l’iPhone, elle sera poursuivie demain par les
          surfaces interactives telles que les tablettes, les tables et les
          murs, qui commencent à devenir des produits commerciaux.</p>
<p>À titre d’exemple, le gouvernement anglais est en
          train d’équiper massivement les écoles de tableaux interactifs.
          Demain ils seront aussi sans doute présents dans les chambres des
          écoliers et interconnectés par Internet. Les enfants pourront y
          faire leurs devoirs, mais aussi jouer, découvrir, expérimenter. Les
          manuels scolaires seront des e-books, signant la fin des cartables
          pesants, les cahiers utiliseront eux aussi du papier interactif qui
          permettra aux professeurs de faire les corrections à distance.</p>
<p>Les travailleurs intellectuels utiliseront aussi
          massivement ces technologies. Dans les salles de réunion traîneront
          des surfaces interactives pour prendre des notes, récupérer des
          documents à présenter, enregistrer les présentations. Bien entendu,
          il restera de nombreux ordinateurs classiques pour certaines tâches.
          La saisie de texte au clavier a encore de beaux jours devant elle,
          et beaucoup seront attachés à consulter leur e-mail ou à naviguer
          sur le Web comme au bon vieux temps. Finalement, le prix déclinant,
          le grand public adoptera aussi progressivement ces outils.</p>
<p>Tout aura changé, et rien n’aura changé : les
          livres, les cahiers, les tableaux, les tables, les murs seront
          toujours là, ils auront la même fonction mais ils ne seront plus
          passifs, ils seront devenus interactifs, contribuant au rêve
          d’<persname>Engelbart</persname> de donner à
          chacun les moyens d’élever ses capacités intellectuelles
          personnelles et collectives.</p>
<div>
            Sources
            <bibl>
<hi>Bau</hi> et <hi>Mackay</hi>, 2008 : Olivier <hi>Bau</hi> et Wendy E. <hi>Mackay</hi>, « OctoPocus : a Dynamic Guide for
            Learning Gesture-Based Command Sets », in <hi>Proceedings of the 21st Annual ACM Symposium on User
            interface Software and Technology</hi>, UIST ‘08 (Monterey, CA,
            19-22 octobre 2008), New York, p. 37-46.</bibl>
<bibl>
<hi>Beaudouin-Lafon</hi>,
            2000 : Michel <hi>Beaudouin-Lafon</hi>,
            « Instrumental Interaction : an Interaction Model for Designing
            Post-WIMP User Interfaces », in <hi>Proceedings of
            the annual SIGCHI Conference on Human Factors in Computing
            Systems</hi>, CHI ‘00 (La Haye, Pays-Bas, 1<hi>er</hi>-6 avril 2000), New York, p. 446-453.</bibl>
<bibl>
<hi>Berners-Lee</hi>
<hi>et al.</hi>, 1994 : Tim <hi>Berners-Lee</hi>, Robert <hi>Cailliau</hi>, Ari <hi>Luptonen</hi>, Henrik <hi>Frystyk Nielsel</hi> et Arthur <hi>Secret</hi>, « The World Wide Web », <hi>Communications of the ACM</hi>, vol. 37 (8), août,
            New York, p. 76-82.</bibl>
<bibl>
<hi>Bier</hi>
<hi>et al.</hi>, 1993 : Eric A. <hi>Bier</hi>, Maureen C. <hi>Stone</hi>, Ken <hi>Pier</hi>,
            William <hi>Buxton</hi> et Tony D. <hi>DeRose</hi>, « Toolglass and Magic Lenses : the
            See-Through Interface », in <hi>Proceedings of the
            20</hi>
<hi>th</hi>
<hi> Annual
            Conference on Computer Graphics and Interactive Techniques</hi>
            (Anaheim, CA, 2-6 août 1993), SIGGRAPH ‘93, New York,
            p. 73-80.</bibl>
<bibl>
<hi>Bolt</hi>, 1980 :
            Richard A. <hi>Bolt</hi>, « Put-That-There :
            Voice and Gesture at the Graphics Interface », in <hi>Proceedings of the 7</hi>
<hi>th</hi>
<hi> Annual Conference on
            Computer Graphics and Interactive Techniques</hi> (Seattle, WA,
            14-18 juillet 1980), SIGGRAPH ‘80, New York, p. 262-270.</bibl>
<bibl>
<hi>Bush</hi>, 1945 :
            Vannevar <hi>Bush</hi>, « As We May Think », <hi>The Atlantic Monthly</hi>, vol. 176, juillet,
            p. 101-108. Réédité dans <hi>Life Magazine</hi>,
            novembre 1945. Réédité et commenté dans <hi>ACM
            interactions</hi>, vol. 3 (2), New York, 1996, p. 35-67.</bibl>
<bibl>
<hi>Callahan</hi>
<hi>et al.</hi>, 1988 : John <hi>Callahan</hi>, Don <hi>Hopkins</hi>, Mark <hi>Weiser</hi> et Ben <hi>Shneiderman</hi>, « An Empirical Comparison of
            Pie vs. Linear Menus », in <hi>Proceedings of the
            annual SIGCHI Conference on Human Factors in Computing
            Systems</hi>, CHI ‘88 (Washington D.C., 15-19 mai 1988), New York,
            p. 95-100.</bibl>
<bibl>
<hi>Chapuis</hi> et <hi>Roussel</hi>, 2005 : Olivier <hi>Chapuis</hi> et Nicolas <hi>Roussel</hi>, « Metisse is not a 3D Desktop »,
            in <hi>Proceedings of the 18th ACM Symposium on User
            Interface Software and Technology</hi>, UIST ‘05 (Seattle, WA,
            23-26 octobre 2005), New York, p. 13-22.</bibl>
<bibl>
<hi>Engelbart</hi>, 1962 :
            Douglas C. <hi>Engelbart</hi>, <hi>Augmenting Human Intellect : A Conceptual
            Framework</hi>, Summary Report on Contract AF 49(638)-1024,
            Stanford Research Institute, octobre.</bibl>
<bibl>
<hi>Engelbart</hi>, 1968 :
            D. C. <hi>Engelbart</hi>, <hi>A
            Research Center for Augmenting Human Intellect</hi>, 90-min. video
            recording, live online hypermedia demonstration/presentation at
            the Fall Joint Computer Conference, San Francisco, CA, 9
            décembre.</bibl>
<bibl>
<hi>Johnson</hi>
<hi>et al.</hi>, 1989 : Jeff <hi>Johnson</hi>, Teresa L. <hi>Roberts</hi>, William <hi>Verplank</hi>, David C. <hi>Smith</hi>, Charles H. <hi>Irby</hi>, Marian <hi>Beard</hi> et Kevin <hi>Mackey</hi>, « The Xerox “Star” : A
            Retrospective », <hi>IEEE Computer</hi>, vol. 22
            (9), septembre, p. 11-29. Réédité dans Ronald M. Baecker, Jonathan
            Grudin, William Buxton et Saul Greenberg, <hi>Human
            Computer Interaction : Toward the Year 2000</hi>, San Francisco,
            1995, p. 53-70.</bibl>
<bibl>
<hi>Kurtenbach</hi> et <hi>Buxton</hi>, 1993 : Gordon <hi>Kurtenbach</hi> et William <hi>Buxton</hi>, « The Limits of Expert Performance
            Using Hierarchic Marking Menus », in <hi>Proceedings
            of the annual SIGCHI Conference on Human Factors in Computing
            Systems</hi>, INTERCHI ‘93 (Amsterdam, 24-29 avril 1993),
            New York, p. 482-487.</bibl>
<bibl>
<hi>Mackey</hi>, 2000 :
            Wendy E. <hi>Mackey</hi>, « Responding to
            Cognitive Overload : Co-adaptation Between Users and Technology »,
            <hi>Intellectica</hi>, vol. 30 (1),
            p. 177-193.</bibl>
<p>
<hi>Mackey</hi>
<hi> et al.</hi>, 2002 : Wendy E. <hi>Mackey</hi>, Catherine <hi>L</hi>
<hi>etondal</hi>,
            Guillaume <hi>Pothier</hi>, Kaare <hi>B</hi>
<hi>ø</hi>
<hi>egh</hi> et Hans Erik <hi>S</hi>
<hi>ørensen</hi>, « The
            Missing Link : Augmenting Biology Laboratory Notebooks », in <hi>Proceeding of the annual ACM Symposium on User
            Interface Software and Technology</hi>, UIST ‘02 (Paris,
            27-30 octobre 2002), New York, p. 41-50.</p>
<bibl>
<hi>Nelson</hi>, 1992 :
            Ted <hi>Nelson</hi>, <hi>Literary
            Machines : The report on, and of, Project Xanadu concerning word
            processing, electronic publishing, hypertext, thinkertoys,
            tomorrow’s intellectual revolution, and certain other topics
            including knowledge, education and freedom</hi>, Sausalito
            (CA).</bibl>
<bibl>
<hi>Perkins</hi>
<hi>et al.</hi>, 1997 : Roderick <hi>Perkins</hi>, Dan Smith <hi>Keller</hi> et Frank <hi>Ludolph</hi>, « Inventing the Lisa User
            Interface », <hi>ACM Interactions</hi>, vol. 4 (1),
            New York, p. 41-53.</bibl>
<bibl>
<hi>Raskin</hi>, J. 2000 :
            Jef <hi>Raskin</hi>, <hi>The
            Humane Interface</hi>, Addison Wesley.</bibl>
<bibl>
<hi>Sellen</hi> et <hi>Harper</hi>, 2001 : Abigail J. <hi>Sellen</hi> et Richard H. R. <hi>Harper</hi>, <hi>The Myth of the
            Paperless Office</hi>, Cambridge (Mass.).</bibl>
<bibl>
<hi>Smith</hi>
<hi>et al.</hi>, 1982 : David Canfield <hi>Smith</hi>, Charles <hi>Irby</hi>, Ralph <hi>Kipball</hi> et Eric <hi>Harslem</hi>, « The Star User Interface : an
            Overview », in <hi>Proceedings of the 1982 National
            Computer Conference</hi>, AFIPS (Houston, Texas, 7-10 juin 1982),
            New York, p. 515-528.</bibl>
<bibl>
<hi>Sutherland</hi>,
            1963 : Ivan E. <hi>Sutherland</hi>,
            « SketchPad : A Man-Machine Graphical Communication System », in
            <hi>Proceedings of the Spring Joint Computer
            Conference</hi>, AFIPS ‘63 (Detroit, Michigan, 21-23 mai 1963),
            New York, p. 329-346.</bibl>
<bibl>
<hi>Weiser</hi>, 1991 :
            Mark <hi>Weiser</hi>, « The Computer for the
            Twenty-First Century »,<hi> Scientific
            American</hi>, vol. 265 (3), septembre, p. 94-104.</bibl>
<bibl>
<hi>Wellner</hi>
<hi>et al.</hi>, 1993 : Pierre <hi>Wellner</hi>, Rich <hi>Gold</hi> et Wendy <hi>Mackay</hi>, « Special Issue on
            Computer-Augmented Environments : back to the Real World », <hi>Communications of the ACM</hi>, vol. 36 (7),
            juillet, New York.</bibl>
<bibl>
<hi>Wellner</hi>, 1993 :
            Pierre <hi>Wellner</hi>, « Interacting with
            Paper on the DigitalDesk »,<hi> Communications of
            the ACM</hi>, vol. 36 (7), juillet, New York, p. 87-96.</bibl>
</div>
</div>
<div>
          Autres références
          <bibl>
<hi>Baecker</hi>
<hi>et al</hi>., 1995 : Ronald M. B<hi>aecker</hi>, Jonathan <hi>Grudin</hi>, William A. S. <hi>Buxton</hi> et Saul <hi>Greenberg</hi>, <hi>Human-Computer
          Interaction : Toward the Year 2000</hi>, San Francisco (CA).</bibl>
<bibl>
<hi>Beaudouin-Lafon</hi>,
          2006 : Michel <hi>Beaudouin-Lafon</hi> (dir.),
          Section Interaction Homme-Machine, <hi>Encyclopédie de
          l’Informatique et des Systèmes d’Information</hi>, dir. Jacky Akoka
          et Isabelle Comyn-Wattiau, Paris.</bibl>
<bibl>
<hi>Erickson</hi> et <hi>McDonald</hi>, 2008 : Thomas <hi>Erickson</hi> et David W. <hi>McDonald</hi> (dir.), <hi>HCI
          Remixed : Reflections on Works That Have Influenced the HCI
          Community</hi>, Cambridge (Mass.).</bibl>
<bibl>
<hi>Moggridge</hi>, 2007 :
          Bill <hi>Moggridge</hi>, <hi>Designing Interactions</hi>, Cambridge (Mass.).</bibl>
<bibl>
<hi>Shneiderman</hi> et <hi>Plaisant</hi>, 2009 : Ben <hi>Shneiderman</hi> et Catherine <hi>Plaisant</hi>,<hi> Designing the
          User Interface : Strategies for Effective Human-Computer
          Interaction</hi>, 5<hi>e</hi> éd., Boston.</bibl>
<bibl>
<hi>Smith</hi> et <hi>Alexander</hi>, 1988 : Douglas K. <hi>Smith</hi> et Robert C. <hi>Alexander</hi>, <hi>Fumbling the
          Future : How Xerox Invented, then Ignored, the First Personal
          Computer</hi>, New York.</bibl>
<bibl>
<hi>Suchman</hi>, 2006 :
          Lucy <hi>Suchman</hi>, <hi>Human-Machine Reconfigurations : Plans and Situated
          Actions</hi>, Cambridge.</bibl>
</div>
</div>
</text>