{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85ffa36a",
   "metadata": {},
   "source": [
    "# to increase the capacite of view in jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce6688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increases the jupyter notebook capacity of data\n",
    "#!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b54f5a0",
   "metadata": {},
   "source": [
    "# 1 - Step\n",
    "## print all files name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a888960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrives file support\n",
    "import glob\n",
    "# inform the path\n",
    "for file_path in glob.iglob('clean_pandas/*.txt'):\n",
    "    file_name = (file_path)\n",
    "    #print(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2b0933",
   "metadata": {},
   "source": [
    "## 1.a\n",
    "### visualize the fille side by side to compare the errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9579053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table\n",
    "import pandas as pd\n",
    "\n",
    "df_clean = pd.read_csv(\"clean_pandas/LDSII_52_Kassow_OnegShabbes_text_clean_BIO.txt\", \n",
    "                       sep=\"\\t\", names=[\"TOKEN\", \"PREDICTION\", \"GOLD\", \"VALIDITY\"])\n",
    "df_hand = pd.read_csv(\"hand_pandas/LDSII_52_Kassow_OnegShabbes_text_beyond_hand_BIO.txt\", \n",
    "                      sep=\"\\t\", names=[\"TOK\"])\n",
    "\n",
    "# convert the dictionary into DataFrame\n",
    "table_clean = pd.DataFrame(df_clean)\n",
    "table_hand = pd.DataFrame(df_hand)\n",
    "\n",
    "# split the column TOK in two GOLD with the IOB format and TOK_ with the tokenized text\n",
    "table_hand[['TOK_','GOLD_bio']] = table_hand.TOK.str.split(\" \",expand=True,)\n",
    "\n",
    "#df['columnF'] = pd.Series(df1['columnF'])\n",
    "table_clean['GOLD']=pd.Series(table_hand['GOLD_bio'])\n",
    "\n",
    "# delete the index\n",
    "blankIndex=[''] * len(table_clean)\n",
    "table_clean.index=blankIndex\n",
    "\n",
    "# delete the column from TABLE_HAND previews columns\n",
    "del table_hand ['TOK']\n",
    "del table_hand ['TOK_']\n",
    "\n",
    "# it allows to display entire table\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None )\n",
    "\n",
    "# it allows to see the columns name or head \n",
    "#print(df.columns)\n",
    "\n",
    "# It makes able to see the first's four lines\n",
    "#print(table_clean.head())\n",
    "\n",
    "# function to compare columns NE-COARSE-LIT x GOLD\n",
    "def compare(x):    \n",
    "    return '1' if x['PREDICTION'] == x['GOLD'] else 'O'\n",
    "\n",
    "table_clean['VALIDITY'] = table_clean.apply(compare, axis=1)\n",
    "\n",
    "#print(table_hand)\n",
    "#print(table_clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a753632a",
   "metadata": {},
   "source": [
    "# 2 - Step\n",
    "\n",
    "## Textes problèmatiques \n",
    "### problèmes avec des langues (greek, japonais, latin, chinois)\n",
    "### problèmes des Upper case\n",
    "### problèmes avec les chifres et les tableaux\n",
    "### problèmes avec certains signes (<,>,«,», )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7986667c",
   "metadata": {},
   "source": [
    "BNU_02_Colin_\n",
    "\n",
    "BNU_05_Dege_\n",
    "\n",
    "CMA_11_2018_Saint-Martin_\n",
    "\n",
    "CMA_8_Buccheri_\n",
    "\n",
    "LDSI_04_Dugast_\n",
    "\n",
    "LDSI_08_Glassner_\n",
    "\n",
    "LDSII_04_Icher_LesOutilsDuCompagnon_\n",
    "\n",
    "LDSII_09_Icher_LetabliDuMenuisier_\n",
    "\n",
    "LDSII_19_Ragazzoli_LireInscrireSurvivreEgypteAncienne_\n",
    "\n",
    "LDSII_27_Dejean_LaStructurationDocumentsElectroniques_\n",
    "\n",
    "LDSII_33_Berra_Thesaurus_\n",
    "\n",
    "LDSII_38_Houdart_ArchitectureTrompeLoeil_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10bdf9c",
   "metadata": {},
   "source": [
    "# 3 - Step\n",
    "## read the csv file ( precision_rappel )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d763a0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure\t\tent_type, partial\tstrict\texact\n",
      "correct\t\t50\t\t\t47\t\t45\t\t47\n",
      "incorrect\t6\t\t\t0\t\t11\t\t9\n",
      "partial\t\t0\t\t\t9\t\t0\t\t0\n",
      "missed\t\t3\t\t\t3\t\t3\t\t3\n",
      "spurious\t31\t\t\t31\t\t31\t\t31\n",
      "possible\t59\t\t\t59\t\t59\t\t59\n",
      "actual\t\t87\t\t\t87\t\t87\t\t87\n",
      "precision\t0.575\t\t0.592\t0.517\t0.54\n",
      "recall\t\t0.847\t\t0.873\t0.763\t0.797\n",
      "f1\t\t\t0.685\t\t0.705\t0.616\t0.644\n"
     ]
    }
   ],
   "source": [
    "# libray to read csv\n",
    "import csv\n",
    "\n",
    "with open('db_results/precision_rappel/BNU_01_Didier_precision_rappel.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91390769",
   "metadata": {},
   "source": [
    "## 3.a \n",
    "### read all file from the database\n",
    "### concatenate them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be4d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# the path to your csv file directory\n",
    "mycsvdir = 'db_results/precision_rappel/'\n",
    "\n",
    "# get all the csv files in that directory (assuming they have the extension .csv)\n",
    "csvfiles = glob.glob(os.path.join(mycsvdir, '*.csv'))\n",
    "\n",
    "# loop through the files and read them in with pandas\n",
    "dataframes = []  # a list to hold all the individual pandas DataFrames\n",
    "for csvfile in csvfiles:\n",
    "    df = pd.read_csv(csvfile)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# concatenate them all together\n",
    "result = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# print out to a new csv file\n",
    "result.to_csv('db_results/all_precision_rappel.csv')\n",
    "#print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f439b1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "path = r'db_results/precision_rappel/' # use your path\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n",
    "df_merged = pd.concat(df_from_each_file, ignore_index=True)\n",
    "df_merged.to_csv( \"db_results/all_merged.csv\")\n",
    "\n",
    "#print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e825974",
   "metadata": {},
   "source": [
    "## 3.b\n",
    "### create the avarage all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c8abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "average = df.groupby(df.columns, axis=1).sum()\n",
    "# print(average)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf069772",
   "metadata": {},
   "source": [
    "## 3.c\n",
    "### save it as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164c4bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='db_results/all_text_average.tsv' mode='w' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# write to file\n",
    "with open(\"db_results/all_text_average.tsv\",'w') as write_csv:\n",
    "    \n",
    "    write_csv.write(average.to_csv(sep='\\t', index=False))\n",
    "    print(write_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c49c2c",
   "metadata": {},
   "source": [
    "## 3.d\n",
    "### print it to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5590f33a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Measure\tent_type\tpartial\tstrict\texact\"\n",
      "\"correct\t204\t\t222\t190\t222\"\n",
      "\"incorrect\t35\t\t0\t49\t17\"\n",
      "\"partial\t0\t\t17\t0\t0\"\n",
      "\"missed\t\t36\t\t36\t36\t36\"\n",
      "\"spurious\t167\t\t167\t167\t167\"\n",
      "\"possible\t275\t\t275\t275\t275\"\n",
      "\"actual\t\t406\t\t406\t406\t406\"\n",
      "\"precision\t0.502\t\t0.568\t0.468\t0.547\"\n",
      "\"recall\t\t0.742\t\t0.838\t0.691\t0.807\"\n",
      "\"f1\t\t0.599\t\t0.677\t0.558\t0.652\"\n"
     ]
    }
   ],
   "source": [
    "# libray to read csv\n",
    "import csv\n",
    "\n",
    "with open('db_results/all_text_average.tsv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "    for row in spamreader:\n",
    "        print(', '.join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb57b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "538ed519",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-76200a7591ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#table_average [\"Measure\"] = table_average [\"N_MEASURE\"].str.strip()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# it allows to see the columns name or head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_average\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Measure\\t\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtable_average\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ent_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/EHESS/dev/env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4296\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# make a table\n",
    "import pandas as pd\n",
    "\n",
    "df_average = pd.read_csv(\"db_results/all_text_average.tsv\", sep=\"\\t\")\n",
    "\n",
    "# convert the dictionary into DataFrame\n",
    "table_average = pd.DataFrame(df_average)\n",
    "\n",
    "#df['birthdate'] = df.birthrate.str.strip() \n",
    "#table_average [\"Measure\"] = table_average [\"N_MEASURE\"].str.strip()\n",
    "# it allows to see the columns name or head \n",
    "print(table_average.columns[\"Measure\\t\"])\n",
    "\n",
    "table_average['ent_type'].replace('\\t', '', regex=True, inplace=True)\n",
    "#df['text'].replace(r'\\s+|\\\\n', ' ', regex=True, inplace=True) \n",
    "\n",
    "# Again, the inplace parameter will change the dataframe without assignment\n",
    "#table_average.rename(columns={\"\": \"MEASURE\"}, inplace=True)\n",
    "\n",
    "\n",
    "# It makes able to see the first's four lines\n",
    "#print(table_average.head())\n",
    "table_average\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71650f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1084bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d46a196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6fb66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db80e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46938a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c78517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2031a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f2ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62078d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
